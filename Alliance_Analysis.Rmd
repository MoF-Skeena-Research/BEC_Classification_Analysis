---
title: "Creating Alliances from Species Groups"
author: "Will MacKenzie & Kiri Daust"
date: "17/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

require(tidyverse)
require(tidymodels)
require(data.table)
require(data.tree)
require(DataExplorer)
require(indicspecies)
require(doParallel)
require(Hmsc)
require(vegan)
require(Matrix)
require(labdsv)
require(gdata)
require(MASS)
require(openxlsx)
require(vegclust)
require(standardize)
require(tictoc)
require(Hmisc)
require(ggplot2)
require(ggdendro)
require(pvclust)
require(dendextend)
require(ape)
require (dbscan)
require(factoextra)
require(fpc)
require(cluster)


source("./_functions/_TabletoTree.R")
source("./_functions/_TreetoTable.R")
source("./_functions/_VegdatSUsummary.R")
cloud_dir <- "F:/OneDrive - Personal/OneDrive/BEC_Classification_Paper/"
#cloud_dir <- "F:/OneDrive - Government of BC/CCISSv12/"
```

Alliance Scripts
2. Build Alliances by Orders from NewML scripts. Focus should be on identifying species groups that reflect different site conditions.
a. COuld use JSDM from Hmsc package to find species - specoes associations and joint species groups related to environmental variables. This would then allow climate change projections (disaggregation of species associations)
a. Use some of the techniques of indicspecies package to create Alliances based on indicator group creation and analysis.
b. Try to build a machine learning model of Alliances?
c. Vegetation and Environment summary of Alliances

3. Do pair-wise analysis of site series within Alliances using high constancy species to analyze site series and create Associations/SubAssociations.4. Document hierarchy

5. Build model to assign new units and unassigned plots
Challenge here is to make a constant list of species between model and new units.
a. Predict membership of new site series (draft BECv13). Noise Clustering to test for novel units that do not fit any existing. Use machine learning to hierarchy
b. Predict Order membership of BECMaster plots that are unassigned to existing site series and add to an Order_unplaced site unit under each Order.

6. Build for non-forested units. Classes based on major site level differences rather than climate and using major species groups (e.g. Hydrophytic Carex spp )
May wish to assign a temporary notree pseudo species to all units that have no trees to help separate forested hierarchy from non-forested hierarchy (Hurdle model)
## Import SU table and BECv12 site series

```{r import data}
vegDat2 <- fread("./clean_tabs/BECMaster_VegR_clean.csv", data.table = FALSE)
#sppMaster <- fread('D:/CommonTables/SpeciesMaster/SpeciesMaster01Dec2020.csv') %>% filter(Codetype == "U")
BECv13_SU <- fread("./clean_tabs/BECv13Analysis_Forest_17Sept2021_SU.csv", stringsAsFactors = FALSE)
BECv13_HierTree <- fread("./clean_tabs/BECv13Hierarchy_v1_22Sept2021_Hierarchy.csv")
levelNames <- c("Formation", "Class", "Order", "Suborder", "Alliance", "Suball", "Assoc", "Subass", "Facies", "Working", "SiteUnit")
BECv13_Hier <- treeToTable(BECv13_HierTree) ## convert matrix to tree
BECv13_Hier <- BECv13_Hier$table

#BECv13_vegSum <- fread('./clean_tabs/BECv13SiteUnitSummary.csv', stringsAsFactors = FALSE)
BECv13_env <- fread('./clean_tabs/BECMaster_env_climate_data.csv', stringsAsFactors = FALSE)
#---------------
vegSum <- VegdatSUsummary(vegDat2,BECv13_SU)

BECv13Hier.data <- left_join(vegSum,BECv13_Hier)

```

```{r reduce summary for alliance analysis, echo=FALSE}
#For each Order
Orders <- unique(BECv13Hier.data$Suborder)
Orders
Order.dat <- BECv13Hier.data %>% filter(Suborder == "SUBORDER CwFd (No Hw ICHxw and xh)")
Order.selected <- Order.dat$SiteUnit %>% as.character
##limit life forms to tree species
#trees <- c(1,2)
constcut <- 55 ##remove species less than cutoff
covercut <- 0
nplots <- 3
##max constancy by species
Spp.highconst <- Order.dat  %>%  group_by(Species) %>%
  summarise(max = max(Constancy, na.rm=TRUE)) %>% filter(max > constcut) %>% dplyr::select(Species) 
Spp.highconst <- Spp.highconst$Species %>% as.character
###only keep species that have high constancy in at least 1 unit
Order.dat2 <- Order.dat[Order.dat$Species %in% Spp.highconst,] %>% dplyr::filter(MeanCov > covercut) %>% filter(nPlots >= nplots)
Order.dat2 <- Order.dat2 %>% dplyr::select(Order,SiteUnit, Species, MeanCov, Constancy)
Order.vegmatx <- Order.dat2 %>% dplyr::select(SiteUnit, Species, MeanCov, Constancy)
Order.vegmatx <- Order.vegmatx %>% pivot_wider(id_cols = SiteUnit, names_from = Species, values_from = c(MeanCov, Constancy))
Order.covmatx <- Order.dat2 %>% dplyr::select(SiteUnit, Species, MeanCov)
Order.covmatx <- Order.covmatx %>% pivot_wider(id_cols = SiteUnit, names_from = Species, values_from = MeanCov) %>% dplyr::select(-SiteUnit)
plot.dat <- left_join(BECv13_SU ,vegDat2 ) %>% filter(SiteUnit %in% Order.selected, Species %in% Spp.highconst) %>% 
  dplyr::select(PlotNumber, Species, Cover) 
plot.dat2 <- plot.dat %>% group_by(PlotNumber,Species) %>% mutate(Cover2 = sum (Cover)) %>% dplyr::select(PlotNumber, Species, Cover2) %>% distinct() %>% as.data.table
plot.spp <- plot.dat2$Species %>% as.data.frame %>% distinct() 
                                                                  
plot.matx <- plot.dat2 %>% pivot_wider(id_cols = PlotNumber, names_from = Species, values_from = Cover2) %>% as.data.frame

```


```{r some hierarchy stats}
siteunits <- unique(Order.dat2$SiteUnit)
siteunits
species.const <- unique(Order.dat2$Species)
species.const
Order_SU <- BECv13_SU %>% filter(SiteUnit %in% siteunits)
fwrite(Order_SU, "./outputs/Order_SU.csv")
### Choose hierarchical level for analysis

class.dat <-
  Order.dat2 %>% dplyr::select(SiteUnit, Order, Species, MeanCov) %>% 
  pivot_wider(id_cols = c(SiteUnit, Order),
    names_from = Species,
    values_from = MeanCov) %>% 
  mutate(Order = ifelse(Order == "", "unplaced", Order)) %>% filter(!SiteUnit == "") %>% 
   replace(is.na(.),0) %>% 
  mutate_if(is.character, as.factor) %>% distinct()

#DataExplorer::create_report(class.dat)
```
```{r environmental summary by site series}

Order_env <- left_join(Order_SU, BECv13_env, by = "PlotNumber") %>% filter(!MAT == -9999) %>% dplyr::select(PlotNumber, SiteUnit,  CMD, DD5, DD1040, bFFP)

Order_env <- unique(Order_env[!is.na(SiteUnit) & SiteUnit != "",])
Order_env3 <- Order_env[,if(.N > 1) .SD, by = .(SiteUnit)]
Order_env3 [,nPlots := length(unique(PlotNumber)), by = .(SiteUnit)]
#SS_envsum <- Order_env3[,.(MeanCov = sum(Cover, na.rm = TRUE)/nPlots[1], Constancy = (.N/nPlots[1])*100, nPlots = nPlots[1]), by = .(SiteUnit,Sp)]
#fwrite(vegSum, './clean_tabs/BECv13SiteUnitSummaryVegData.csv')

```


```{r explore data}
require(ExPanDaR)
# export data and code to a notebook
ExPanD(Order_env, export_nb_option = TRUE)

# open a shiny app
ExPanD(df) 


```

```{r cluster of veg summary}
VegMatrix <- as.data.frame(Order.vegmatx)
SiteUnit <- VegMatrix$SiteUnit
rownames(VegMatrix) <- VegMatrix$SiteUnit
VegMatrix <- VegMatrix %>% dplyr::select(-SiteUnit)
VegMatrix[is.na(VegMatrix)] <- 0
Vegchord = decostand(VegMatrix,"normalize")
```

```{r tidy models kmeans}
###tidy models kmeans clustering
points <- 
  Vegchord %>% 
  dplyr::select(-cluster)

kclust <- kmeans(points, centers = 3)
kclust
summary(kclust)

clustered_pts <- tidy(kclust, points)
tidy(kclust)
glance(kclust)

ggplot(labelled_points, aes(x1, x2, color = cluster)) +
  geom_point(alpha = 0.3)


kclusts <- 
  tibble(k = 2:20) %>%   mutate(kclust = map(k, ~kmeans(points, .x)), tidied = map(kclust, tidy),  glanced = map(kclust, glance), augmented = map(kclust, augment, points) )

clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()


p1 <- 
  ggplot(assignments, aes(x = x1, y = x2)) +
  geom_point(aes(color = .cluster), alpha = 0.8) + 
  facet_wrap(~ k)
plot(p1)
```



```{r cluster analysis}
dd <- dist(Vegchord)
hc <- hclust(dd, method = "ward.D2")

flexbeta <- function (dis,beta) 
{
  alpha <- (1-beta)/2
  out <- agnes(dis,meth='flex',par.method=alpha)
  out
}
hc <- flexbeta(dd,-0.25)
hc <- as.hclust(hc)
dend <- as.dendrogram(hc)
####plots from ape package
plot(as.phylo(hc), type = "unrooted", cex = 0.5,no.margin = TRUE, lab4ut = "axial")

plot(as.phylo(hc), cex = 0.5, label.offset = 0.5)
#plot(as.phylo(hc), type = "cladogram", cex = 0.5, label.offset = 0.5)
#plot(as.phylo(hc), type = "fan")
```


```{r}
library(cluster)
fit <- kmeans(dd, 10)
#clusplot(Vegchord, fit$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
out <- cbind(Plots, clusterNum = fit$cluster)
head(out)
write.csv(out, "./outputs/ClusterMembership.csv", row.names = FALSE)

# Centroid Plot against 1st 2 discriminant functions
library(fpc)
plotcluster(dd, fit$cluster)

##Import SU table of plots desired for cluster analysis
#SUhier <- read.csv("FebHierarchyLevelSU.csv", stringsAsFactors = FALSE)
#### Reduce vegdata to those listed in SUHier

########Function to define optimal eps
dbscan::kNNdistplot(dd, k =  4)
abline(h = 0.4, lty = 2)
###compute DBSAN using two different packages
set.seed(123)
# fpc package
res.fpc <- fpc::dbscan(dd, eps = 0.4, MinPts = 4)
# dbscan package
res.db <- dbscan::dbscan(dd, 0.4, 4)
#Make sure that both version produce the same results:
  
  all(res.fpc$cluster == res.db)

 # The result can be visualized as follow:
    
    fviz_cluster(res.fpc, dd, geom = "point")
    
    
  dbscan(data, eps, MinPts = 5, scale = FALSE, 
       method = c("hybrid", "raw", "dist"))
# Compute DBSCAN using fpc package
set.seed(123)
db <- fpc::dbscan(dd, eps = 0.15, MinPts = 5, method = "dist")
# Plot DBSCAN results
plot(db, df, main = "DBSCAN", frame = FALSE)
# Print DBSCAN
print(db)
## or plot with factoextra
fviz_cluster(db, dd, stand = FALSE, frame = FALSE, geom = "point")
km.res <- kmeans(dd, 5, nstart = 25)
fviz_cluster(km.res, dd, frame = FALSE, geom = "point")

```


```{r joint distribution species model}
#find species that jointly move with environment


```


```{r create updated VPro hierarchy}
##convert matrix to tree, add in new units
levelNames <- c("Formation", "Class", "Order", "Suborder", "Alliance", "Suball", "Assoc", "Subass", "Facies", "Working", "SiteUnit")
testReverse <- tableToTree(hierWide = copy(SUhier),levelNames) ## convert matrix to tree
newBEC2 <- newBEC %>% rename(Name = .pred_class)
pred.ID <- newBEC2 %>% select(Name) %>% distinct() %>% left_join(testReverse) %>% select(Name, ID) ## Parent Code for new predictions
newBEC3 <- left_join(newBEC2, pred.ID, by = "Name") %>% select(-Name) %>% rename(Parentnew = ID, Name = SiteUnit)

testReverse2 <- left_join(testReverse, newBEC3) %>% mutate(Parent, ifelse(!is.na(Parentnew), Parentnew, Parent)) %>% 
            select(-Parent, -Parentnew) %>% rename (Parent = 4) %>% select(ID, Name, Parent, Level)
testReverse2$Parent <- ifelse(testReverse2$Parent == 1, "", testReverse2$Parent)
fwrite(testReverse2, "./outputs/UpdatedVPROHierarchyTree2.csv")

```

```{r merge predictions into hierarchy }



```


## Tuning run to identify appropriate hyper parameters. Only needs to be run a single time for a particular model development

```{r model tuning, include = FALSE, echo = FALSE}

# BEC_tunemodel <- rand_forest(mtry = tune(), min_n = tune(), trees = 501) %>%
#   set_mode("classification") %>%
#   set_engine("ranger", importance = "impurity") #or "permutations
# 
# # randf_spec <- rand_forest(trees = 500) %>%
# #   set_engine("randomForest") %>%
# #   set_mode("classification")
# 
# BEC_tuneworkflow <- workflow() %>%
#   add_model(BEC_tunemodel) %>%
#     add_recipe(BEC_recipe)
# 
# ranger_tune_detail <-
#   grid_regular(
#     mtry(range = c(1, 20)),
#     min_n(range = c(2, 10)),
#     levels = 5)
# 
# cv_metrics <- metric_set(accuracy, roc_auc, j_index)
# 
# v = 10
# reps = 5
# set.seed(345)
# BEC_cvfold <- vfold_cv(BEC_all, 
#                          v = v, 
#                          repeats = reps, 
#                          strata = Class)
# # re-run the tuning with the explicit parameter sets
# set.seed(4556)
# doParallel::registerDoParallel()
# 
# ranger_regular_tune <-
#   tune_grid(BEC_tuneworkflow,
#             resamples = BEC_cvfold,
#             metrics = cv_metrics,
#             grid = ranger_tune_detail)
# 
# autoplot(ranger_regular_tune) ##plots the results
# 
# bestacc <- select_best(ranger_regular_tune, metric = "accuracy")
# bestroc <- select_best(ranger_regular_tune, metric = "roc_auc")
# bestj <- select_best(ranger_regular_tune, metric = "j_index")

```

## Run cross validation model of all data using tuning from previous step. Can only be run with enough replicates
```{r define cv model with tuned parameters, echo = TRUE }
# define model with set parameters from tuning

split_data <- initial_split(model_data, prop = 0.6, strata = defense)
training_data <- training(split_data)
testing_data <- testing(split_data)


BEC_fmodel <- rand_forest(mtry = 5, min_n = 2, trees = 501) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "impurity") #or "permutations

BEC_cv_workflow <- workflow() %>% 
  add_model(BEC_fmodel) %>% 
  add_recipe(BEC_recipe)

v = 10
reps = 5
  
set.seed(345)
BEC_cvfold <- vfold_cv(BEC_good, 
                         v = v, 
                         repeats = reps, 
                         strata = Class)
cv_metrics <- metric_set(accuracy, roc_auc, j_index, sens, spec)

set.seed(130)
doParallel::registerDoParallel()
BEC_cv_fitted <- 
  BEC_cv_workflow %>% 
  fit_resamples(resamples = BEC_cvfold, metrics = cv_metrics, control = control_resamples(save_pred = TRUE))
```

## Collect accuracy metrics and predictions and improperly predicted site units
```{r collect metrics and predictions, echo = TRUE }
# collect accuracy metrics  
cv_results <- BEC_cv_fitted  %>% collect_metrics(summarize = FALSE)
cv_results_sum <- BEC_cv_fitted  %>% collect_metrics()
BEC.pred <- BEC_cv_fitted %>% collect_predictions()# collect predictions
BEC.predx <- left_join( BEC.pred, SU_names)
### accuracy by siteunit
BEC.pred_acc <- BEC.pred %>% 
  group_by(Class) %>% 
  accuracy(Class, .pred_class)
#Summarize prediction
BEC.pred2 <- BEC_cv_fitted %>% collect_predictions(summarize = TRUE)# collect predictions
BEC.pred3 <- left_join(SU_names, BEC.pred2)

## Identify misplaced site units
MisID <- BEC.pred3 %>% select(SiteUnit, Class, .pred_class) %>% mutate(compare = if_else(Class == .pred_class, "Same", "Diff")) %>% filter(compare == "Diff")# %>% rename("SiteUnit" = SiteUnit)
fwrite(MisID, "Misplaced Site Series in Classes.csv")

##ID where there are different classifications predicted by fold **** this is not aligning SU_names properly
# BEC.pred_cv <- BEC_cv_fitted %>% collect_predictions(summarize = FALSE) %>% left_join(SU_names) %>% select(SiteUnit, Class, .pred_class) %>% group_by_all() %>% summarize(numcv = n())#distinct# dplyr::rename(BEC.pred = 3) %>% 
# setDT(BEC.pred_cv, key = c("SiteUnit"))
# BEC.pred_cv[, N := .N, by = key(BEC.pred_cv)]                # count rows per group
# class.diff <- BEC.pred_cv[N > 1]

```
## review and reassign site units to correct hierarchy units
```{r reassign units}
##Update class by MisID in BEC_all (to build final model) and in Hier.clean (to update the hierachy table)
UpdateClass <- MisID %>% select(SiteUnit, .pred_class)
Hier_update <- left_join(Hier.clean, UpdateClass, by  = "SiteUnit") %>% mutate(newClass = coalesce(.pred_class, Class)) %>% select(-Class, -.pred_class) %>% rename(Class = newClass) %>% select(ID, Class, everything())
```

```{r reverse function to write hierarhcy back into Vpro format}
levelNames <- c("Region", "Class", "Order", "Suborder", "Alliance", "Suball", 
"Assoc", "Subass", "Facies", "SiteUnit")

tableToTree <- function(hierWide, levelNames){
  levelID <- data.table(Name = levelNames, Level = 1:length(levelNames))
  
  levs <- melt(hierWide, id.vars = "ID")
  levs[,ID := NULL]
  levs <- unique(levs)
  levs[levelID, Level := i.Level, on = c(variable = "Name")]
  
  hierWide[,ID := NULL]
  hierWide[,Root := "TempRoot"]
  setcolorder(hierWide,c(ncol(hierWide),1:(ncol(hierWide)-1)))
  paths <- tidyr::unite(hierWide, "pathString", na.rm = T, sep = "_")
  tr <- as.Node(paths,pathDelimiter = "_")
  tr$Set(Lab = tr$Get("name"))
  tr$Set(name = 1:tr$totalCount)
  dat <- ToDataFrameNetwork(tr,"Lab",direction = "climb")
  dat <- as.data.table(dat)
  setnames(dat, old = c("from","to","Lab"), new = c("Parent","ID","Name"))
  dat[levs, Level := i.Level, on = c(Name = "value")]
  setcolorder(dat,c("ID","Name","Parent","Level"))
  return(dat)
}


testReverse <- tableToTree(hierWide = copy(Hier.clean),levelNames)
```



```{r C5 decision tree}
#For interpretation of hierarchy
#Cross-validation.

#BEC_C5_recipe <- recipe(Class ~ .,  data = BEC_all)# %>%
    #step_center(all_predictors()) %>%
 # step_scale(all_predictors())
BEC_C5_model <- decision_tree(min_n = 2) %>% #, trees = NULL, min_n = NULL)# trees = 5, min_n = 2min_n = 10specify that the model is a random forest
  #set_args(mtry = tune()) %>% specify that the `mtry` parameter needs to be tuned
  set_engine("C5.0") %>%  #, num.threads = (cores-1), importance = "impurity, ) %>% select the engine/package that underlies the model
   set_mode(mode = "classification")

 # set the workflow
BEC_C5_workflow <- workflow() %>%
  add_recipe(BEC_recipe) %>%
  add_model(BEC_C5_model)
#
BECmodel.C5 <- fit(BEC_C5_workflow, BEC_all)
out <- butcher(BECmodel.C5, verbose = TRUE)


C5model <- C5.0_train(class.dat, Class, minCases = 2)
C5model <- C5.0(x=class.dat[-1], y = class.dat$Class)
C5model
summary(C5model)
plot(C5model)

## build model for prediction

gc()

 BECmodel.var <- pull_workflow_fit(BECmodel.tidy)$fit
BEC.pred <-   as.data.frame(BECmodel.var$predicted)
MisID <- cbind(classID,BEC.pred)%>% dplyr::rename(BEC.pred = 3) %>% mutate(compare = if_else(Class == BEC.pred, "Same", "Diff"))
fwrite(MisID, "Misplaced Site Series in Classes.csv")
###Variable importance
varimp <- as.data.frame(BECmodel.var$importance)
covcount <- nrow(varimp)


#saveRDS(BGCmodel.tidy, file = paste("./BGC_models/WNAv12_Zone_", covcount, "_Var_tidyrf3.rds"))
#parsed <- parse_model(BGCmodel.var)
#write_yaml(parsed, "my_model.yml")
saveRDS(BECmodel.tidy, file= paste("./BEC_models/Forest_Classes_rf.rds"))

```


```{r}
BEC_split <- initial_split(class.dat, strata = Class, p = .8)
BEC_train <- training(BEC_split)
BEC_test <- testing(BEC_split)


BEC_model <- rand_forest(trees = 101, mtry = tune()) %>%# min_n = 10specify that the model is a random forest
  #set_args(mtry = tune()) %>% specify that the `mtry` parameter needs to be tuned
  set_engine("randomForest", num.threads = (cores-1)) %>%  #, importance = "impurity, ) %>% select the engine/package that underlies the model
   set_mode("classification")

 # set the workflow
BEC_workflow <- workflow() %>%
  add_recipe(BEC_recipe) %>%
  add_model(BEC_model)
#
## build model for prediction
BECmodel.train <- BEC_workflow %>% fit(BEC_train)
 BECmodel.var <- pull_workflow_fit(BECmodel.train)$fit
 BECmodel.var


 # trainIndex <- createDataPartition(class.dat$Class, p = .7,
#                                   list = FALSE,
#                                   times = 1)
# 
# 
# BEC_train <- XAll[ trainIndex,]
# BEC_train$BEC <- as.factor(BEC_train$BEC)
# BEC_test  <- XAll[-trainIndex,]# %>% droplevels()

BECmodel_train <- ranger(BEC ~ ., data = BEC_train[-1],
                           num.trees = 501,  seed = 12345,
                            splitrule =  "extratrees", #""gini",
                            #always.split.variables = c("DD5","CMD.total", "PPT_JAS"), #,
                            #split.select.weights = var.weight.vec,
                    mtry = 5,
                          #max.depth = .5,
                    min.node.size = 5,
                           importance = "permutation", write.forest = TRUE, classification = TRUE)

BECmodel_train

 test.pred <- predict(BECmodel.train, new_data = BEC_test[,-c(1)])
  BEC.pred <- as.data.frame(test.pred) %>% tibble::rownames_to_column() %>% dplyr::rename("BEC.pred" = ".pred_class")

BEC.test <- BEC_test %>% select(Class) %>% cbind(BEC.pred) %>%  select( -rowname) %>% mutate_if(is.character, as.factor)
levels(BEC.test$BEC.pred) <- levels(BEC.test$BEC)
BEC_accuracy <- BEC.test %>%                   # test set predictions
  accuracy(truth = Class, BEC.pred)
 table(BEC_accuracy)
```

```{r review misassigned SS}

```

```{r predict placement of new SS and plots}



```

