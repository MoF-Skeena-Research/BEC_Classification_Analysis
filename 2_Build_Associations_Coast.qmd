---
title: "Build Associations for LMH77"
author: "William H MacKenzie"
date: "06/09/2024"
format:
  typst:
    toc: false
    toc-depth: 1
    toc-title: Contents
    section-numbering: 1.1.1
    columns: 1
editor: source
execute:
  echo: false
  error: false
  warning: false
  message: false
  fig.width: 6
  fig.height: 4
  fig.align: 'center'
  fig.cap: true
  fig.pos: H
  out.width: '100%'
  dev: pdf
  fig.ext: pdf
  cache: false
  fig.retina: 2
  dpi: 600
  fig.asp: 1.5
  fig.path: "./figures/"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
require(tidyverse)
require(DBI)
require(data.table)
require(cluster)
require(dendextend)
require(dynamicTreeCut)
require(gtable)
require(gtsummary)
require(colorspace)
require(openxlsx)
require(tictoc)
require(labdsv)
require(indicspecies)
require(Polychrome)
require(ggdendro)
require(purrr)
require(ggplotify)
require(grid)
require(data.tree)
library(stats)
set.seed(1279)
source("../BEC_R_working/_functions/_bec_dist.R")
source("../BEC_R_working/_functions/_bec_dist_matrix.R")
source("../BEC_R_working/_functions/_combine_taxa.R")
source("../BEC_R_working/_functions/_combine_taxa_strata.R")
#source("../BEC_R_working/_functions/_lump_species2.R")
source("../BEC_R_working/_functions/_create_su_vegdata.R")
source("../BEC_R_working/_functions/_create_analysis_vegsum.R")
source("../BEC_R_working/_functions/_TabletoTree.R")
source("../BEC_R_working/_functions/_TreetoTable.R")
source("../BEC_R_working/_functions/_add_vars.R")
source("../BEC_R_working/_functions/_do_pairwise.R")
source("../BEC_R_working/_functions/_create_diagnostic_veg.R")
source("../BEC_R_working/_functions/_return_similar_pairs.R")
source("../BEC_R_working/_functions/_read_sppmaster.R")
source("../BEC_R_working/_functions/_combined_su.R")
source("../BEC_R_working/_functions/_create_veg_sum.R")
#source('../BEC_R_working/_functions/_create_veg_sum_all.R')
source('../BEC_R_working/_functions/_build_species_ordering.R')
source('../BEC_R_working/_functions/_format_veg_table.R')
source('../BEC_R_working/_functions/_format_veg_table_strata.R')
source('../BEC_R_working/_functions/_encode_veg_sum.R')
source('../BEC_R_working/_functions/_create_dendro.R')
source('../BEC_R_working/_functions/_create_dendro_all.R')
source('../BEC_R_working/_functions/_create_dendro_bybgc.R')
source('../BEC_R_working/_functions/_draw_dendro_split.R')
source('../BEC_R_working/_functions/_cluster_groups.R')
source('../BEC_R_working/_functions/_TabletoTree.R')
source('../BEC_R_working/_functions/_build_species_ordering_hier.R')
source("../BEC_R_working/_functions/_cluster_by_spp_group.R")
```

# Introduction
This script compares site unit summary vegetation data to identify associations and subassociations within the Coast Forested BGCs. The analysis is based on a agglomerative clustering approach, which groups site units based on their vegetation characteristics.
First we test the separation of zonal sites for proper designation in mapping.

#### Read in data

Vegetation data is read in from saved .RDS file generated from the BECMaster cleaning scripts. 
A compiled SU table is build from all BGC \_SU tables stored in the coast guide Vpro database. 
Taxonomy is read in from the species taxonomy database. 
A species lumping code table is read in from the Correlation2_Spp_lump.accdb database and the vegetation data is lumped using the lump_species function.

```{r load data, echo=FALSE}
veg.dat <- readRDS("./clean_data/Analysis_BECMaster_Veg.rds") ### named veg.dat
taxon.all <- read_sppmaster()
#taxon.all <- read_sppmaster(database = "C:/Users/whmacken/OneDrive/BCSpeciesList/SpeciesTaxonomyMaster.accdb")

taxon.lifeform <- taxon.all %>%
  filter(Codetype == "U" | Codetype == "X" | Codetype == "D") %>%
  dplyr::select(Code, ScientificName, EnglishName, Lifeform) %>%
  distinct()
 tree_seedlings <- taxon.lifeform %>% filter(Lifeform %in% c("1", "2")) %>% mutate(Code = paste0(Code, "D")) %>% pull(Code)
trees <- taxon.lifeform %>% filter(Lifeform %in% c("1", "2")) %>% pull(Code)
veglump <- dbConnect(
  odbc::odbc(),
  .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/BC_Correlation2_Vpro_2023/Correlation2_Spp_lump.accdb;")
lump <- dbReadTable(veglump, "CorrelationII_Lump")
dbDisconnect(veglump)
veg.dat2 <- combine_taxa(vegdata = veg.dat, lump, use.subtaxa = FALSE)
db <- "D:/BC_Correlation2_Vpro_2023/published_sorts/CoastArea_Sorts.accdb"
#db <- "D:/BC_Correlation2_Vpro_2023/Coast_Association_Exercise.accdb"
su <- combined_su(db)
su <- su %>%
  filter(!grepl('X|unplaced|omit|support|nudum', SiteUnit))  %>% arrange(SiteUnit)#
su <- su %>%
  filter(grepl('CWH|CDF|MH', bgc))  %>% arrange(SiteUnit)
#   filter(grepl('01', SiteUnit)) ###zonal specific
su2 <- su %>% select(-SiteUnit.orig) %>%
filter(!bgc %in% c('CWHvh3', 'CWHwh1', 'CWHwh2', 'CWHvh3', 'MHwh')) %>%
  mutate(SiteUnit = str_replace(SiteUnit, "[ab]$", ""))
###BGC specific|CWHms

bgc.unique <- unique(su2$bgc)
ss.unique <- su2 %>% select(SiteUnit, bgc) %>% distinct
ss.count <- length(ss.unique$SiteUnit)
 becmaster <- dbConnect(odbc::odbc(), .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/BECMaster/BECMaster_fixing.accdb;")
plot.env <- dbReadTable(becmaster, "BECMaster_fixing_Env")
plot.edatope <- dbReadTable(becmaster, "BECMaster_fixing_edatopic")
dbDisconnect(becmaster)

#asmr.codes <- fread("./inputs/asmr_codes.csv")
remove = c("Gg", "Ro", "Gs", "Rt", "Gb", "00", "/x", "Bb", "Br", "/Fm", "Fl")
becdb <- dbConnect(odbc::odbc(), .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/OneDrive - Government of BC/BECdb_Working/BECdb_ver13_2026.accdb;")
BGC_all <- dbReadTable(becdb, "tblBGC_UnitsWorkingandArchive") %>% 
  filter(is.na(VersionRetired)) %>% select(FSRegion, BGC_NoSpace)
edatopic <- dbReadTable(becdb, "Edatopic_v13_3") %>% #filter(is.na(Ignore)) %>% 
  mutate(rSMR = paste0("rSMR", substr(Edatopic, 2, 2))) %>% 
    mutate(SNR = substr(Edatopic, 1, 1)) %>% 
 filter(startsWith(Source, "BEC")) %>% select(BGC, rSMR, SNR, SS_NoSpace, Edatopic) %>% distinct %>% filter(!str_detect(SS_NoSpace, paste(remove, collapse = "|"))) %>% 
  mutate(SiteUnit = gsub("/", "_", SS_NoSpace)) 
dbDisconnect(becdb)

rsmr_asmr.long <- fread("../aSMR_X_rSMR/outputs/modelled_aSMR_by_rSMR_long.csv") %>% filter(cmd.type == "CMD", PERIOD == "1961_1990")
SS.edatopic <- left_join(edatopic, rsmr_asmr.long, by = c("BGC", "rSMR")) %>%
  #mutate(SiteUnit = gsub("/", "_", SiteUnit)) %>%
  select(BGC, rSMR, SNR, SiteUnit, Edatopic, aSMR) %>%
  #filter(!is.na(rSMR_value)) %>% 
  distinct()
SS.edatopic.range <- SS.edatopic %>% group_by(SiteUnit) %>% 
  summarise(SNR.range = paste0(min(SNR), "_", max(SNR)), rSMR = paste0(min(rSMR), "_", max(rSMR)), aSMR = paste0(min(aSMR), "_", max(aSMR)) ) %>%
  ungroup() %>% 
  mutate(SiteUnit = gsub("/", "_", SiteUnit)) %>%
  select(SiteUnit, SNR.range, rSMR, aSMR)
#%>% 
  #mutate(rSMR = as.numeric(substr(rSMR, nchar(rSMR), nchar(rSMR))))


## export list of site units in the analysis with columns for all hierarchical units. This file can be edited to hardwire site series group membership
### ONLY RUN ONCE. CHECK AT END OF PROCESS THAT ALL NAMES ARE ACCOUNTED FOR
    # hierarchy_ss <- ss.unique %>% 
    # mutate(Subass = "", Association = "", assoc_method = "", Suball = "", Alliance = "", Subord = "", Order = "", Class = "") %>%
    # arrange(SiteUnit)
    #fwrite(hierarchy_ss,  "./hierarchy/coast_siteunits_hierarchy_membership.csv")

bgc.units<- dbConnect(
  odbc::odbc(),
  .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/OneDrive - Government of BC/BECdb_Working/BECdb_ver13_2026.accdb;")
bgcv12 <- dbReadTable(bgc.units, "tblBGC_UnitsWorkingandArchive")
dbDisconnect(bgc.units)
bgcv13 <- bgcv12 %>% filter(is.na(VersionRetired)) %>% select(BGC_NoSpace, SiteClassificationStatus)

```
add in other summary tables (e.g. USA)
```{r}
usa_units <- fread("./usa.summary.units/USA_prepped_units.csv")
```

## Cluster analysis and dendrogram of all site units

The agglomerative clustering algorithm AGNES successively groups site units based on dissimilarity. It successively merges site units from the bottom up (most similar units get grouped first). Because units or initial clusters may have near equal dissimilarity to neighbours in two directions, the algorithm may not be able to maintain an exact ordering of dissimilarity. We evaluate the cluster analysis using two metrics. 
1) The cophenetic correlation coefficient (CCC) evaluate how well a hierarchical clustering dendrogram preserves the original pairwise distances between observations. The closer CCC is to 1, the better it represents the original distance matrix. Lower numbers indicate that some branchlets of the dendrogram can be associated with more than one branch. 
2) The agglomerative coefficient (AC) is a metric that quantifies the strength of the clustering structure. The closer AC is to 1 indicates strong clustering structure and the observations are tightly grouped by low dissimilarity. This will be affected by the breadth/size of the analysis where a larger number of site units will tend to have lower AC values.

We chose to use the clustering method that maximizes the CCC. We tested a number of methods: complete, average, single, ward,  weighted, and flexible (at a wide range of settings). The "average" method consistently produced the highest cophenetic values so we applied this as the standard method for clustering.

In the dendrograms, the red line represents the minimum threshold for separating site units into separate subassociations. This is set at 10% dissimilarity, but in some BGCs we separate some site series to as low as 7% dissimilarity.
The green line represents the dissimilarity threshold for an association. The initial threshold is set at 20% based on review.




```{r build pair.wise similarity matrix, echo=FALSE, message=FALSE, warning=FALSE}}

key.site.indicators <- c("POPUTRI", "LYSIAME", "GAULSHA", "OPLOHOR", "ELLIPYR","ATHYFIL", "RUBUSPE", "EQUIARV", "GYMNDRY", "VALESIT", "CASSMER", "LUETPEC", "POLYMUN", "STRUSPI", "RHODGRO", "EMPENIG", "NEPHCRI", "PICESIT")#,  "TIARELLA", "DRYOEXP" "PICESIT", )
reduced.exceptions <- c("SPHAGNUM", "CLADONIA", "CLADINA", "RACOMITR", "MNIUM")
# reduced.lifeforms = c(1,2)
reduced.lifeforms <- c(9, 10, 11)#1, 2, 
### select units to run
#su2 <- su2 %>% filter(grepl('101', SiteUnit))# %>%
#  mutate(SiteUnit = gsub("\\.(1|2)$", "", SiteUnit))
# %>% filter(!grepl('ms',SiteUnit))
#fwrite(su2, "./CoastGuide_Forest_101_SU.csv")

su_working <- su2 #su_hier %>%
#mutate(unit_working = ifelse(!is.na(unit_assigned) & unit_assigned != "", unit_assigned, SiteUnit)) %>% select(PlotNumber, unit_working) %>% rename(SiteUnit = unit_working)
#tic()
vegsum.pairs <- do_pairwise(veg.dat2, 
  su = su_working, minimportance = 0.1, minconstancy = 60,
  noiseconstancy = 10,
  minplots = 1,  minor = 1,
  use.ksi = FALSE, ksi = key.site.indicators, ksi.value = 1.5,
  reduce.lifeform = TRUE, reduced.lifeforms = reduced.lifeforms, reduction = .01,
  reduced.exceptions = reduced.exceptions,
  add_vegsum_table = usa_units
)
toc()
xx <- vegsum.pairs %>%  dplyr::filter(Unit1 == "ARBMEN_PSEMEN_GAUSHA")
unit.compare <- vegsum.pairs %>%
  select(Unit1, Unit2, BEC.sim.min, BEC.sim.mean , BEC.sim.max, diff.ratio.x, diff.ratio.y, diff.ratio, nplots.x, nplots.y, unit.diag.sum.x, unit.diag.sum.y) %>% filter(nplots.x>0) %>% mutate(metric.diff = BEC.sim.max - BEC.sim.min) %>%
 distinct()
unit.compare$bgc1 <- stringr::word(unit.compare$Unit1, 1, sep = "\\_")
unit.compare$bgc2 <- stringr::word(unit.compare$Unit2, 1, sep = "\\_")

unit.compare <- vegsum.pairs %>% filter(nplots.x > 0, Unit1 != Unit2) %>%  
  select(Unit1, Unit2, Species, BEC.sim.min, nplots.x, unit.diag.sum.x) %>% 
  distinct()

bec_dist_matrix <- bec_dist_matrix(vegsum.pairs, distance = "BEC.sim.min") %>% data.frame
write.csv(bec_dist_matrix, "./clean_tabs/Coast_Forest_Distance_matrix.csv")

```

### Evaluate site series within each BGC

1.  Identify site series that have fewer than 5 plots (difficult to quantitatively analyse)

2.  Identify site series that have low diagnostic potential.

3.  Compare site series within each BGCs to identify site series below the minimal threshold to separate

Some units with few plots or low diagnostics fall out as singles in the first pass cluster analysis. These are reviewed and merging rules applied before re-running the cluster analysis.
List of site series with too few plots or low diagnostic potential for reliable analysis 
```{r site series with too few plots, echo=FALSE}
#| label: tab-too-few-plots
#| fig-cap: "Site Units with Fewer than 5 Plots"
#| warning: false
#| fig-align: "left"

compared <- unit.compare
ss_too.few <- compared %>%
  select(Unit1, nplots.x) %>% 
  filter(nplots.x < 5) %>% 
  rename("Number of Plots" = nplots.x, "Site Unit" = Unit1) %>% 
  distinct()
# low.num <- gt::as_gtable(gt::gt(ss_too.few) %>% gt::fmt_number(decimals = 0)|> gt::tab_options(table.font.size = 10), plot = TRUE)
num_units <- ss_too.few %>% 
  pull(`Site Unit`) %>% 
  n_distinct()
col_label <- paste0("Site Unit (", num_units, ")")

  gt::gt(ss_too.few ) %>%
  gt::fmt_number(columns = "Number of Plots", decimals = 0) %>%
  gt::tab_options(table.font.size = 10) %>%
  gt::cols_label(`Site Unit` = col_label) %>% 
  gt::tab_options(table.font.size = 10)

```

```{r site series with low diagnostic potential, echo=FALSE}
#| label: tab-low-diagnostic
#| fig-cap: "Site Units with Low Diagnostic Potential"
#| warning: false
#| fig-align: "left"

ss_low.diag <- compared %>%
  select(Unit1, unit.diag.sum.x)  %>% 
  filter(unit.diag.sum.x < 30) %>% 
  rename("Diagnostic Potential" = unit.diag.sum.x, "Site Unit" = Unit1) %>%
  distinct()
# low.diag.pot <- gt::as_gtable(gt::gt(ss_low.diag) %>% gt::fmt_number(decimals = 2)|> gt::tab_options(table.font.size = 10), plot = TRUE)
num_units <- ss_low.diag %>% 
  pull(`Site Unit`) %>% 
  n_distinct()
col_label <- paste0("Site Unit (", num_units, ")")

  gt::gt(ss_low.diag) %>%
  gt::fmt_number(columns = "Diagnostic Potential", decimals = 0) %>%
  gt::tab_options(table.font.size = 10) %>%
  gt::cols_label(`Site Unit` = col_label) %>% 
  gt::tab_options(table.font.size = 10)
```
```{r site units that are too similar, echo=FALSE}
#| label: tab-sites-similar
#| tbl-cap: paste0("Site Series pairs with poor differentiation (BEC.sim >= .90)")
#| tbl-cap-location: top
#| warning: false
#| tbl-align: "left"
ss_similar <- compared %>%
  select(Unit1, Unit2, BEC.sim.min) %>%
  dplyr::filter(BEC.sim.min >= .85) %>% mutate(Units = paste0(Unit1, " vs ", Unit2)) %>%
  select(-Unit2, -Unit1) %>% 
  rename("Similarity" = BEC.sim.min, "Site Units" = Units) %>%
  distinct() 
# low.diff <- gt::as_gtable((gt::gt(ss_similar) |> gt::fmt_number(decimals = 2)|> gt::tab_options(table.font.size = 10) |> gt::cols_width(Site.Units ~ gt::px(250))), plot = TRUE, text_grob = gridtext::richtext_grob)
gt::gt(ss_similar) |> gt::fmt_number(decimals = 2)|> gt::tab_options(table.font.size = 10) 
```


Probably the best approach is separate site units into already defined Orders or SubOrders based on tree species composition, then cluster within hierarchical unit. 
```{r}
source("../BEC_R_working/_functions/_evaluate_clustering_by_group2.R")

### Chunk here could feed in major analysis groups such as Orders
hierarchy <- fread("./hierarchy/coast_siteunits_hierarchy_membership.csv") %>% mutate_if(is.logical, as.character)
#### Code for checking the list of units in the hierarchy and updating if required################

missing_in_hierarchy <- su2 %>%
  distinct(SiteUnit) %>%
  anti_join(hierarchy %>% distinct(SiteUnit), by = "SiteUnit") %>%
  mutate(flag = "in_su2_not_hierarchy")

extra_in_hierarchy <- hierarchy %>%
  distinct(SiteUnit) %>%
  anti_join(su2 %>% distinct(SiteUnit), by = "SiteUnit") %>%
  mutate(flag = "in_hierarchy_not_su2")

hierarchy_updated <- hierarchy %>%
  left_join(extra_in_hierarchy, by = "SiteUnit") %>%
  bind_rows(
    missing_in_hierarchy %>%
      mutate(across(everything(), as.character))  # ensure type consistency
  )

hierarchy_updated2 <- hierarchy_updated %>%
  mutate(
unit_working = ifelse(
  grepl("_[A-Za-z]", SiteUnit),
  sub(".*_(.*)$", "\\1", SiteUnit),
  unit_working# Extract the trailing letter only when present
    )
  )

#fwrite(hierarchy_updated2, "./hierarchy/coast_siteunits_hierarchy_membership.csv")
# from ML upper hierarchy
### add in working units from within bgc clustering

within.bgc.clst <-  fread("./hierarchy/within_bgc_clusters.csv")

hierarchy_updated2[within.bgc.clst, unit_working := group_unit1, on = c("SiteUnit" = "unit1")]

fwrite(hierarchy_updated2, "./hierarchy/coast_siteunits_hierarchy_membership.csv")
```


```{r}
group.table <- hierarchy %>% select(SiteUnit, Order)


clustering_results <- evaluate_clustering_by_group(
  unit.compare = unit.compare,
  grouping_table = group.table,
  clst_method = "average",
  siteunit_col = "SiteUnit",
  analgroup_col = "Order")

gt::gt(clustering_results) %>%
  gt::fmt_number(columns = c("CCC", "AC"), decimals = 3) |>
  gt::tab_options(table.font.size = 10) |>
  gt::cols_label(
    CCC = "Cophenetic Correlation",
    AC = "Agglomerative Coefficient"
  )

```

### Step2. Feed in hard-coded merged site units from a previous process
Zonal groups from independent scripts
Some 102 groups are from a manual merge in the intial correlation work. Most site units have low plot numbers and were grouped on major indicators and 'logical' climatic grouping 
```{r merge reviewed singles, echo=FALSE}
source("../BEC_R_working/_functions/_assign_manual_cluster.R")
zonal.groups = fread("./hierarchy/LMH77_zonal_assoc_memberships.csv")
# su_zonal <- assign_manual_cluster(su.tab = su2, cluster.file = zonal.groups ,
#                                  group_col = "assigned_assoc",
#                                    use_last_step = FALSE)
hierarchy <- fread("./hierarchy/coast_siteunits_hierarchy_membership.csv") %>% mutate_if(is.logical, as.character) 
## update membership of zonal associations
hierarchy[zonal.groups, unit_working := unit_assigned, on = "SiteUnit"] 

hierarchy <- as.data.frame(hierarchy) %>% mutate(unit_method = ifelse(SiteUnit %in% zonal.groups$SiteUnit, "Zonal", unit_method)) %>% as.data.frame
fwrite(hierarchy, "./hierarchy/coast_siteunits_hierarchy_membership.csv")

su_hier <- left_join(su2, hierarchy)
# 
su_updated <- su_hier %>% 
  mutate(SiteUnit = ifelse(!is.na(unit_working) & unit_working != "", unit_working, SiteUnit)) %>%
  select(PlotNumber, SiteUnit, Order) 

```

```{r build pair.wise similarity matrix, echo=FALSE, message=FALSE, warning=FALSE}}

su_working <- su_updated #su_hier %>%
#mutate(unit_working = ifelse(!is.na(unit_assigned) & unit_assigned != "", unit_assigned, SiteUnit)) %>% select(PlotNumber, unit_working) %>% rename(SiteUnit = unit_working)
#tic()
vegsum.pairs <- do_pairwise(veg.dat2, 
  su = su_working, minimportance = 0.1, minconstancy = 60,
  noiseconstancy = 10,
  minplots = 1,  minor = 1,
  use.ksi = TRUE, ksi = key.site.indicators, ksi.value = 1.5,
  reduce.lifeform = TRUE, reduced.lifeforms = reduced.lifeforms, reduction = .25,
  reduced.exceptions = reduced.exceptions
)
toc()

unit.compare <- vegsum.pairs %>% filter(nplots.x > 0, Unit1 != Unit2) %>%  
  select(Unit1, Unit2, Species, BEC.sim.min, nplots.x, unit.diag.sum.x) %>% 
  distinct()

# bec_dist_matrix <- bec_dist_matrix(vegsum.pairs, distance = "BEC.sim.min") %>% data.frame
# write.csv(bec_dist_matrix, "./clean_tabs/LMH77_Forest_Distance_matrix.csv")

```

### flag units with few plots or low diagnostics to remove before running clustering or to view within dendrogram.
```{r site dendrogram split, echo=FALSE}
source("../BEC_R_working/_functions/_bec_dist_matrix.R")
few.plots.threshold = 7
low.diag.threshold = 30

    unit.compare2 <- unit.compare
    include.few.plots <- TRUE
    if (include.few.plots) {
    unit.few <- unit.compare2 %>%
        filter(nplots.x < few.plots.threshold) %>%
        select(Unit1) %>% #, nplots.x) %>%
        distinct()}
    include.low.diag <- TRUE
    if (include.low.diag) {
      unit.simple <- unit.compare2 %>%
        filter(unit.diag.sum.x < low.diag.threshold) %>%
        select(Unit1) %>% #, unit.diag.sum.x) %>%
        distinct()
    }
    unit.poor <- bind_rows(unit.few, unit.simple) 
    
    unit.compare.poor <- unit.compare %>% filter(Unit1 %in% unit.poor$Unit1 & Unit2 %in% unit.poor$Unit1)
    unit.compare.good <- unit.compare %>% filter(!Unit1 %in% unit.poor$Unit1 & !Unit2 %in% unit.poor$Unit1) 
    #hierarchy.groups <- hierarchy %>% filter(SiteUnit %in% anal.group.choose$SiteUnit) %>% filter(!is.na(unit_assigned), unit_assigned != "")
    #anal.group.choose[hierarchy.groups, SiteUnit := unit_assigned, on = "SiteUnit"]
    unit.compare.anal <- unit.compare.good 

```


### First Iteration: Stepwise cluster lumping by analysis group (Order)

Successively merges units at a specified dissimilarity threshold.

```{r}
source("../BEC_R_working/_functions/_stepwise_cluster_lumping.R")
su_order <- su_updated %>% filter(Order == "CWH") %>% arrange(SiteUnit)
order_siteunits <- su_order  %>% select(SiteUnit) %>% distinct() %>% pull(SiteUnit)
unit.compare.anal <- unit.compare.good %>% filter(Unit1 %in% order_siteunits, Unit2 %in% order_siteunits)

unit_lineage <- stepwise_cluster_lumping(
  unit.compare = unit.compare.anal,
  combine.level = 0.4, ## Alliance Level
  max.steps = 1,
  stop.no.change = TRUE,
  verbose = TRUE,
  initial.groups = NULL
)
last_column <- names(unit_lineage)[ncol(unit_lineage)]
unit_lineage<- unit_lineage %>%
  select(OriginalUnit, all_of(last_column)) %>% rename(unit_working_update = 2)

#su_updated <- left_join(su2, unit_lineage, by = c("SiteUnit" = "OriginalUnit")) %>% distinct %>% mutate(Association = Step3_Group) %>% select(PlotNumber, SiteUnit, Association)

#ss.unique <- su2 %>% select(SiteUnit) %>% distinct()

su_cluster1 <- left_join(su_order, unit_lineage, by = c("SiteUnit" = "OriginalUnit")) %>%  mutate(SiteUnit = unit_working_update) %>%  select(-unit_working_update)
#   select(SiteUnit, Set_Association, Association_modelled) #%>% mutate(Association_modelled = sub(".*_", "", Association_modelled))
# su.no.group <- su_unit_lineage %>% filter(is.na(Association_modelled)) %>% select(SiteUnit, Set_Association) %>% mutate(Association_modelled = "no group") %>%
#   mutate(SiteUnit = paste0(SiteUnit, "_no_group")) %>% distinct()
# 
# #su_unit_lineage <- su_unit_lineage %>% filter(!is.na(Association_modelled))
# 
# su_updated3 <- left_join(su_updated, su_unit_lineage,  by = c("SiteUnit" = "SiteUnit")) %>% select(PlotNumber, SiteUnit, Association_modelled)
    
    association_results <- cluster_by_spp_group(
  unit.compare.anal,
  analysis_tab = NULL,
  group_var = NULL,
  group = NULL,
  cut.level = 0.4,
  combine.level = 0.2,
  include.low.diag = TRUE,
  low.diag.threshold = 1,
  include.few.plots = TRUE,
  few.plots.threshold = 1,
  output.file = "initial_association_memberships.csv"
 )
zz <- fread("initial_association_memberships.csv")

```
#### Export vegetation summary tables of site units by prospective associations

```{r build veg guide summary and export to excel, echo = FALSE, warning=FALSE, message=FALSE}
require(openxlsx)
require(tictoc)
library(stringr)
data.path = "D:/OneDrive - Government of BC/GitHub_data"
author <- "alliance1-CWH "
su_update <- su_cluster1 %>% rename(Working = SiteUnit) %>% as.data.table
setDT(su2)
su3 <- merge(su2, su_update[, .(PlotNumber, Working)], by = "PlotNumber", all.x = TRUE)

#assoc.list <- coast.units %>% filter(!is.na(Association_clst)) %>% group_by(Association_clst) %>% mutate(n=n()) %>% filter(n>2) %>% distinct(Association_clst) %>% pull(Association_clst)
unit.list <- su3 %>% filter(!is.na(Working)) %>%  select(SiteUnit, Working) %>% distinct() %>% group_by(Working) %>% mutate(n=n()) %>% filter(n > 0) %>% arrange(desc(n)) %>%  distinct(Working) %>% pull(Working)
assoc.choose = "Step1_Grp5"
vegsum.wbk <- createWorkbook()
for(unit.choose in unit.list){
#assoc.choose = "assoc-MC102"
assoc.plots <- su3 %>% filter(Working %in% unit.choose) %>% select(PlotNumber, SiteUnit)# %>% mutate(SiteUnit = gsub(" ", "", SiteUnit)) %>% mutate(SiteUnit = str_replace(SiteUnit, "/", "_"))
su.assoc <- left_join(assoc.plots, su3) #%>%  mutate(SiteUnit = Working) %>% distinct()
veg.dat.assoc <- veg.dat2 %>% filter(PlotNumber %in% su.assoc$PlotNumber)
# vegsum.wbk <- createWorkbook()
# #bgc.choose = "CDFmmtab2"
# #for(bgc.choose in bgc.list){
vegSum <-
  create_veg_sum(vegdata = veg.dat.assoc, siteunit.tbl = su.assoc, siteunit.var = "Working", minconstancy = 60, noiseconstancy = 10, strata.by = "Lifeform", lumpfile = NULL)


#indic.order <- build_species_ordering_hier(vdat = veg.dat.assoc, vsum = vegSum, code.lump=lump, siteUnits = su.assoc, hier.level = "Working")
veg.sum.table <- format_veg_table(vsum = vegSum, spp=taxon.lifeform, strata.by = "Lifeform") #, species.order = indic.orderstrat)
## add in aSMR and SNR from edatopic tables conversion and climate summary data
su.units <- su.assoc %>% select(SiteUnit) %>% distinct %>% pull(SiteUnit)
#  mutate(SiteUnit = str_replace(SiteUnit, "\\.(1|2)$", "")) %>% 

ss.edatopic <- SS.edatopic.range %>% filter(SiteUnit %in% su.units) %>% select(SiteUnit, rSMR, SNR.range, aSMR) %>% t %>% as.data.frame() 
# Promote first row to column names
colnames(ss.edatopic) <- ss.edatopic[1, ]
ss.edatopic <- ss.edatopic[-1, ]

ss.edatopic <- as.data.frame(ss.edatopic) %>% rownames_to_column(var = "Scientific name") %>%
  mutate(Layer = "Env") %>% select(Layer, `Scientific name`, everything()) %>%  mutate(`Common name` = "Env")
full.table <- bind_rows(veg.sum.table, ss.edatopic)
openxlsx::addWorksheet(vegsum.wbk, sheetName = unit.choose)
openxlsx::writeData(vegsum.wbk, sheet = unit.choose, full.table)
}

saveWorkbook(vegsum.wbk, paste0("./vegsum.tables/LMH77_draft_assoc_tables_", author, ".xlsx"), overwrite = TRUE)

```

### Second Iteration: Compare first iteration cluster units
Run again to see if any of the initial groups now merge with other associations

```{r}

# key.site.indicators <- c("POPUTRI", "LYSIAME", "GAULSHA", "OPLOHOR", "ELLIPYR","ATHYFIL", "RUBUSPE", "EQUIARV", "GYMNDRY", "VALESIT", "CASSMER", "LUETPEC", "POLYMUN", "STRUSPI", "RHODGRO", "EMPENIG")#,  "TIARELLA", "DRYOEXP" "PICESIT", )
# reduced.exceptions <- c("SPHAGNUM", "CLADONIA", "CLADINA", "RACOMITR", "MNIUM")
# reduced.lifeforms = c(1,2)
#reduced.lifeforms <- c(9, 10, 11)
### select units to run
#su2 <- su2 %>% filter(grepl('101', SiteUnit))# %>%
#  mutate(SiteUnit = gsub("\\.(1|2)$", "", SiteUnit))
# %>% filter(!grepl('ms',SiteUnit))
#fwrite(su2, "./CoastGuide_Forest_101_SU.csv")
tic()
vegsum.pairs <- do_pairwise(veg.dat2, 
  su = su_cluster1, minimportance = 0.1, minconstancy = 60,
  noiseconstancy = 10,
  minplots = 1,  minor = 1,
  use.ksi = FALSE, ksi = key.site.indicators, ksi.value = 1.5,
  reduce.lifeform = TRUE, reduced.lifeforms = reduced.lifeforms, reduction = .1,
  reduced.exceptions = reduced.exceptions
)
toc()

unit.compare.assoc <- vegsum.pairs %>%
  select(Unit1, Unit2, BEC.sim.min, BEC.sim.mean , BEC.sim.max, diff.ratio.x, diff.ratio.y, diff.ratio, nplots.x, nplots.y, unit.diag.sum.x, unit.diag.sum.y) %>% filter(nplots.x>0) %>% mutate(metric.diff = BEC.sim.max - BEC.sim.min) %>%
 distinct()
unit.compare$bgc1 <- stringr::word(unit.compare$Unit1, 1, sep = "\\_")
unit.compare$bgc2 <- stringr::word(unit.compare$Unit2, 1, sep = "\\_")

unit.compare.assoc<- vegsum.pairs %>% filter(nplots.x > 0, Unit1 != Unit2) %>%  
  select(Unit1, Unit2, Species, BEC.sim.min, nplots.x, unit.diag.sum.x) %>% 
  distinct()

association_results <- cluster_by_spp_group(
  unit.compare.assoc,
  analysis_tab = NULL,
  group_var = NULL,
  group = NULL,
  cut.level = 0.4,
  combine.level = 0.2,
  include.low.diag = TRUE,
  low.diag.threshold = 1,
  include.few.plots = TRUE,
  few.plots.threshold = 1,
  output.file = "initial_association_memberships.csv"
 )
zz <- fread("initial_association_memberships.csv")
```

### Second Iteration: Stepwise cluster lumping into new proto associations
Merge initial groups into new groups 
```{r}
unit_lineage2 <- stepwise_cluster_lumping(
  unit.compare = unit.compare.assoc,
  combine.level = 0.25,
  max.steps = 20,
  stop.no.change = TRUE,
  verbose = TRUE,
  initial.groups = NULL
)
last_column <- names(unit_lineage2)[ncol(unit_lineage2)]
unit_lineage2 <- unit_lineage2 %>%
  select(OriginalUnit, all_of(last_column)) %>% rename(unit_working_update = 2)

#su_updated <- left_join(su2, unit_lineage, by = c("SiteUnit" = "OriginalUnit")) %>% distinct %>% mutate(Association = Step3_Group) %>% select(PlotNumber, SiteUnit, Association)

#ss.unique <- su2 %>% select(SiteUnit) %>% distinct()

su_cluster2 <- left_join(su_cluster1, unit_lineage2, by = c("SiteUnit" = "OriginalUnit")) %>%  mutate(SiteUnit = unit_working_update) %>%  select(-unit_working_update)
```
#### Export second iteration vegetation summary tables of site units by prospective associations

```{r build veg guide summary and export to excel, echo = FALSE, warning=FALSE, message=FALSE}
require(openxlsx)
require(tictoc)
library(stringr)
data.path = "D:/OneDrive - Government of BC/GitHub_data"
author <- "cluster2-20"
su_update <- su_cluster2 %>% rename(Working = SiteUnit) %>% as.data.table
setDT(su2)
su3 <- merge(su2, su_update[, .(PlotNumber, Working)], by = "PlotNumber", all.x = TRUE) %>% as.data.frame

#assoc.list <- coast.units %>% filter(!is.na(Association_clst)) %>% group_by(Association_clst) %>% mutate(n=n()) %>% filter(n>2) %>% distinct(Association_clst) %>% pull(Association_clst)
unit.list <- su3 %>% filter(!is.na(Working)) %>%  select(SiteUnit, Working) %>% distinct() %>% group_by(Working) %>% mutate(n=n()) %>% filter(n > 5) %>% arrange(desc(n)) %>%  distinct(Working) %>% pull(Working)
#assoc.choose = "Step3_Grp1"
vegsum.wbk <- createWorkbook()
for(unit.choose in unit.list){
#assoc.choose = "assoc-MC102"
assoc.plots <- su3 %>% filter(Working %in% unit.choose) %>% select(PlotNumber, SiteUnit)# %>% mutate(SiteUnit = gsub(" ", "", SiteUnit)) %>% mutate(SiteUnit = str_replace(SiteUnit, "/", "_"))
su.assoc <- left_join(assoc.plots, su3) %>%  as.data.frame %>% distinct()
veg.dat.assoc <- veg.dat2 %>% filter(PlotNumber %in% su.assoc$PlotNumber)
# vegsum.wbk <- createWorkbook()
# #bgc.choose = "CDFmmtab2"
# #for(bgc.choose in bgc.list){
vegSum <-
  create_veg_sum_all(vdat = veg.dat.assoc, siteUnits = su.assoc, strata.by = "Lifeform")

#indic.order <- build_species_ordering_hier(vdat = veg.dat.assoc, vsum = vegSum, code.lump=lump, siteUnits = su.assoc, hier.level = "Working")
veg.sum.table <- format_veg_table2(vsum = vegSum, spp=taxon.lifeform)
openxlsx::addWorksheet(vegsum.wbk, sheetName = unit.choose)
openxlsx::writeData(vegsum.wbk, sheet = unit.choose, veg.sum.table)
}

saveWorkbook(vegsum.wbk, paste0("./vegsum.tables/LMH77_draft_assoc_tables_", author, ".xlsx"), overwrite = TRUE)

```


Run a third iteration to see if any of the initial groups now merge with other associations

```{r}

key.site.indicators <- c("POPUTRI", "LYSIAME", "GAULSHA", "OPLOHOR", "ELLIPYR","ATHYFIL", "RUBUSPE", "EQUIARV", "GYMNDRY", "VALESIT", "CASSMER", "LUETPEC", "POLYMUN", "STRUSPI", "RHODGRO", "EMPENIG")#,  "TIARELLA", "DRYOEXP" "PICESIT", )
reduced.exceptions <- c("SPHAGNUM", "CLADONIA", "CLADINA", "RACOMITR", "MNIUM")
# reduced.lifeforms = c(1,2)
reduced.lifeforms <- c(9, 10, 11)
### select units to run
#su2 <- su2 %>% filter(grepl('101', SiteUnit))# %>%
#  mutate(SiteUnit = gsub("\\.(1|2)$", "", SiteUnit))
# %>% filter(!grepl('ms',SiteUnit))
#fwrite(su2, "./CoastGuide_Forest_101_SU.csv")
tic()
vegsum.pairs <- do_pairwise(veg.dat2, 
  su = su_cluster2, minimportance = 0.1, minconstancy = 60,
  noiseconstancy = 10,
  minplots = 1,  minor = 1,
  use.ksi = TRUE, ksi = key.site.indicators, ksi.value = 1.5,
  reduce.lifeform = TRUE, reduced.lifeforms = reduced.lifeforms, reduction = .1,
  reduced.exceptions = reduced.exceptions
)
toc()

unit.compare.assoc <- vegsum.pairs %>%
  select(Unit1, Unit2, BEC.sim.min, BEC.sim.mean , BEC.sim.max, diff.ratio.x, diff.ratio.y, diff.ratio, nplots.x, nplots.y, unit.diag.sum.x, unit.diag.sum.y) %>% filter(nplots.x>0) %>% mutate(metric.diff = BEC.sim.max - BEC.sim.min) %>%
 distinct()
unit.compare$bgc1 <- stringr::word(unit.compare$Unit1, 1, sep = "\\_")
unit.compare$bgc2 <- stringr::word(unit.compare$Unit2, 1, sep = "\\_")

unit.compare.assoc<- vegsum.pairs %>% filter(nplots.x > 0, Unit1 != Unit2) %>%  
  select(Unit1, Unit2, Species, BEC.sim.min, nplots.x, unit.diag.sum.x) %>% 
  distinct()

association_results <- cluster_by_spp_group(
  unit.compare.assoc,
  anal.groups=NULL,
  cut.level = 0.7,
  combine.level = 0.2,
  include.low.diag = TRUE,
  low.diag.threshold = 1,
  include.few.plots = TRUE,
  few.plots.threshold = 1,
  output.file = "initial_association_memberships.csv"
 )
zz <- fread("initial_association_memberships.csv")
```


#### Export vegetation summary tables of site units by prospective associations

```{r build veg guide summary and export to excel, echo = FALSE, warning=FALSE, message=FALSE}
require(openxlsx)
require(tictoc)
library(stringr)
data.path = "D:/OneDrive - Government of BC/GitHub_data"
author <- "cluster2-15"
su_update <- su_cluster3 %>% rename(Working = SiteUnit) %>% as.data.table
setDT(su2)
su3 <- merge(su2, su_update[, .(PlotNumber, Working)], by = "PlotNumber", all.x = TRUE)

#assoc.list <- coast.units %>% filter(!is.na(Association_clst)) %>% group_by(Association_clst) %>% mutate(n=n()) %>% filter(n>2) %>% distinct(Association_clst) %>% pull(Association_clst)
unit.list <- su3%>% filter(!is.na(Working)) %>%  select(SiteUnit, Working) %>% distinct() %>% group_by(Working) %>% mutate(n=n()) %>% filter(n>=1) %>%  distinct(Working) %>% pull(Working)
#assoc.choose = "Step3_Grp1"
vegsum.wbk <- createWorkbook()
for(unit.choose in unit.list){
#assoc.choose = "assoc-MC102"
assoc.plots <- su3 %>% filter(Working %in% unit.choose) %>% select(PlotNumber, SiteUnit)# %>% mutate(SiteUnit = gsub(" ", "", SiteUnit)) %>% mutate(SiteUnit = str_replace(SiteUnit, "/", "_"))
su.assoc <- left_join(assoc.plots, su3) #%>%  mutate(SiteUnit = Working) %>% distinct()
veg.dat.assoc <- veg.dat2 %>% filter(PlotNumber %in% su.assoc$PlotNumber)
# vegsum.wbk <- createWorkbook()
# #bgc.choose = "CDFmmtab2"
# #for(bgc.choose in bgc.list){
vegSum <-
  create_veg_sum_all(vdat = veg.dat.assoc, siteUnits = su.assoc, strata.by = "Lifeform")

#indic.order <- build_species_ordering_hier(vdat = veg.dat.assoc, vsum = vegSum, code.lump=lump, siteUnits = su.assoc, hier.level = "Working")
veg.sum.table <- format_veg_table2(vsum = vegSum, spp=taxon.lifeform)
openxlsx::addWorksheet(vegsum.wbk, sheetName = unit.choose)
openxlsx::writeData(vegsum.wbk, sheet = unit.choose, veg.sum.table)
}

saveWorkbook(vegsum.wbk, paste0("./vegsum.tables/LMH77_draft_assoc_tables_", author, ".xlsx"), overwrite = TRUE)

```

Look at edatopic space between units

```{r joint distribution between unit edatopic comparison}
library(infotheo)
library(dplyr)
library(tidyr)
library(purrr)

# Step 1: Prepare edatopic data
plot.eda <- plot.edatope %>% select(PlotNumber, SNR, aSMR) %>% distinct()  %>%
  mutate(
    SNR = factor(SNR, levels = c("A", "B", "C", "D", "E"), ordered = TRUE),
    aSMR.code = recode(aSMR, "0" = "XD", "1" = "ED", "2" = "VD", "3" = "MD", "4" = "SD", "5" = "F", "6" = "M", "7" = "VM", "8" = "W", "9" = "VW"),
    #rSMR = factor(aSMR, levels = c("0", "1", "2", "3", "4", "5", "6", "7", "8"), ordered = TRUE),
    edatopic = interaction(aSMR.code, SNR,  drop = TRUE) 
  )%>% drop_na

# Step 2: Join with associations and filter
assoc.test <- su_updated %>% left_join(plot.eda, by = "PlotNumber")  %>% 
  drop_na(edatopic) %>%
  mutate(aSMR.code = factor(aSMR.code, levels = c("XD", "ED", "VD", "MD", "SD", "F", "M", "VM", "W", "VW"), ordered = TRUE)) %>% 
  mutate(Unit = as.factor(Association_modelled))
  #filter(Association_modelled %in% c("Step3_Grp9", "Step3_Grp24", "Step3_Grp55")) %>%

# Ensure aSMR is an ordered factor from driest to wettest
assoc.test2 <- assoc.test %>% 
  group_by(Unit, aSMR.code) %>%
  mutate(n = n()) %>%  ungroup() %>%
  group_by(Unit) %>% 
  mutate(nplots = n(), percent = 100 * n / nplots, mean.asmr = mean(aSMR)) %>%
  ungroup() %>%
  filter(percent >= 15) 

asmr_percent <- assoc.test2 %>%
  mutate(Unit = as.factor(Association_modelled)) %>% 
  #filter(Unit %in% c("Step3_Grp1", "Step3_Grp2", "Step3_Grp3", "Step3_Grp4", "Step3_Grp5", "Step3_Grp6", "Step3_Grp7", "Step3_Grp8", "Step3_Grp9", "Step3_Grp10"))%>% 
  count(Unit, aSMR.code, aSMR) %>%
  group_by(Unit) %>%
  mutate(percent = 100 * n / sum(n), mean.asmr = mean(aSMR)) %>%
  ungroup()%>%
  filter(percent >= 15)  # Remove classes <10%


# Reorder Unit factor levels by mean.asmr
unit_order <- asmr_percent %>%
  distinct(Unit, mean.asmr) %>%
  arrange(desc(mean.asmr)) %>%
  pull(Unit)

asmr_percent <- asmr_percent %>%
  mutate(Unit = factor(Unit, levels = unit_order))

ggplot(asmr_percent, aes(x = aSMR.code, y = fct_reorder(Unit, desc(mean.asmr)), fill = percent)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "C", direction = -1, name = "Percent") +
  labs(
    title = "aSMR Distribution by Association (Heatmap)",
    x = "aSMR",
    y = "Association"
  ) +
  theme_minimal(base_size = 8) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major = element_blank()
    
# asmr_palette <- c(
#   "XD" = "black",
#   "ED" = "red",
#   "VD" = "purple",
#   "MD" = "orange",
#   "SD" = "yellow",
#   "F"  = "lightgreen",
#   "M"  = "darkgreen",
#   "VM" = "blue",
#   "W"  = "lightblue",
#   "VW" = "darkblue"
# )
# 
# ggplot(asmr_percent, aes(x = percent, y = Unit, fill = aSMR.code)) +
#   geom_col(position = "stack") +
#   scale_fill_manual(values = asmr_palette, name = "aSMR") +
#   labs(
#     title = "Percent of Plots by aSMR for Each Association",
#     x = "Percent of Plots",
#     y = "Association"
#   ) +
#   theme_minimal(base_size = 12) +
#   theme(
#     axis.text.y = element_text(size = 8),
#     panel.grid.major.y = element_blank())
    
# library(plotly)
# 
# p <- ggplot(asmr_percent, aes(x = aSMR.code, y = percent, fill = aSMR.code)) +
#   geom_col() +
#   facet_wrap(~ Unit, ncol = 4) +
#   theme_minimal()
# 
# ggplotly(p)


  )
```


```{r joint distribution between unit edatopic comparison}
compute_js_similarity_pairs <- function(assoc_data, threshold = 0.7) {
  library(dplyr)
  library(tidyr)
  library(tibble)

  # Step 1: Prepare joint frequency matrix
  joint_freqs <- assoc_data %>%
    count(Association_modelled, edatopic) %>%
    pivot_wider(names_from = edatopic, values_from = n, values_fill = 0) %>%
    column_to_rownames("Association_modelled")
  joint_freqs <- joint_freqs[, order(colnames(joint_freqs))]

  # Step 2: Jensen-Shannon Divergence functions
  kl_div <- function(p, q) {
    sum(ifelse(p > 0, p * log(p / q), 0))
  }

  jsd <- function(p, q) {
    m <- 0.5 * (p + q)
    0.5 * kl_div(p, m) + 0.5 * kl_div(q, m)
  }

  js_similarity <- function(p, q) {
    1 - sqrt(jsd(p, q))
  }

  # Step 3: Compute similarity matrix
  prob_matrix <- sweep(joint_freqs, 1, rowSums(joint_freqs), FUN = "/")
  n_units <- nrow(prob_matrix)
  similarity_matrix <- matrix(NA, nrow = n_units, ncol = n_units)

  for (i in 1:n_units) {
    for (j in 1:n_units) {
      p <- as.numeric(prob_matrix[i, ])
      q <- as.numeric(prob_matrix[j, ])
      similarity_matrix[i, j] <- js_similarity(p, q)
    }
  }

  rownames(similarity_matrix) <- rownames(prob_matrix)
  colnames(similarity_matrix) <- rownames(prob_matrix)

  # Step 4: Extract similar pairs above threshold
  similar_pairs <- as.data.frame(similarity_matrix) %>%
    rownames_to_column("Unit1") %>%
    pivot_longer(-Unit1, names_to = "Unit2", values_to = "Similarity") %>%
    filter(Unit1 != Unit2, Similarity >= threshold) %>%
    arrange(desc(Similarity))

  return(list(similar_pairs = similar_pairs, similarity_matrix = similarity_matrix))
}
result <- compute_js_similarity_pairs(assoc.test2, threshold = 0.7)

similar_pairs <- result$similar_pairs
similarity_matrix <- result$similarity_matrix

```


```{r joint distribution between unit edatopic comparison}
# Convert similarity matrix to dissimilarity (distance)
edaphic_matrix <- as.dist(1 - similarity_matrix)

# Perform hierarchical clustering
edaphic.dist <- hclust(distance_matrix, method = "average")  # You can also try "ward.D2", "complete", etc.

draw_edaphic_dendro <- function(dist.mtrx = edaphic_matrix, subass.level = .1, assoc.level = .2, alliance.level = .4, cut.level = .5){
  singles.count = 0
  singles.list = data.frame(SiteUnit = character(), stringsAsFactors = FALSE)
  eda_clst <- agnes(dist.mtrx,
                   diss = TRUE, stand = TRUE,
                   method = "average")
    dendro_hc <- as.hclust(eda_clst)
  dendro_hc.dend <- as.dendrogram(dendro_hc)

  if (!is.null(cut)){
    dendro_hc.dend <- cut(dendro_hc.dend, h = cut.level)
  }
  n <- length(dendro_hc.dend$lower)
  for (i in 1:n){
    dendro_hc.dend.i <- dendro_hc.dend$lower[[i]]
    n2 <- length(dendro_hc.dend.i)
    if (n2 == 1) {singles.count = singles.count + 1}
    if (n2 == 1) {singles.list <- rbind(singles.list, x = setNames(as.data.frame(partition_leaves(dendro_hc.dend.i)), names(singles.list)))}
    if (n2 == 1) next
    # plot(dendro_hc.dend.i, main = paste0("Cluster Dendrogram of Site Units: branch ", i, " at hcut = ", h))
    # }
    #   dend.co <- stats::cophenetic(dendro_hc.i)
    # dend.dis <- as.dist(dis.matrix)
    # cophenetic <- cor(dend.dis, dend.co) %>% round(2)
    # cophenetic ## shows how well the clusters align with the data >0.7 is considered good
    # coph_annotation <- data.frame(x = 9, y=.85, label = paste0("Cophenetic:",cophenetic))
    hcdata <- dendro_data(dendro_hc.dend.i, type = "rectangle")
    yy <- ggplot() +
      # Draw cluster segments
      geom_segment(data = segment(hcdata), 
                   aes(x = x, y = y, xend = xend, yend = yend)) +
      
      # Label leaves
      geom_text(data = label(hcdata), 
                aes(x = x, y = y, label = label, hjust = 0), 
                size = 3) +
      
      # Add shaded band between 0.07 and 0.10
      annotate("rect", xmin = -Inf, xmax = Inf, ymin = subass.level - .03, ymax = subass.level,
               fill = "red", alpha = 0.15) +
      annotate("rect", xmin = -Inf, xmax = Inf, ymin = assoc.level - .02, ymax = assoc.level + .02,
               fill = "darkgreen", alpha = 0.15) +
      annotate("rect", xmin = -Inf, xmax = Inf, ymin = alliance.level - .02, ymax = alliance.level + .02,
               fill = "purple", alpha = 0.15) +
      # Additional horizontal lines
      # geom_hline(yintercept = assoc.level + .02, linetype = "dashed", color = "green") +
      # geom_hline(yintercept = assoc.level - .02, linetype = "dashed", color = "green") +
      # geom_hline(yintercept = subass.level - .03, linetype = "dashed", color = "red") +
      # geom_hline(yintercept = subass.level, linetype = "dashed", color = "red") +
      # geom_hline(yintercept = alliance.level +2, linetype = "dashed", color = "purple") +
      # geom_hline(yintercept = alliance.level -2, linetype = "dashed", color = "purple") +
      # Add labels
      geom_text(aes(x = 0, y = subass.level - .015, label = "Subassociation", hjust = 0),
                angle = 90, color = "grey30", size = 3) +
      geom_text(aes(x = 0, y = assoc.level, label = "Association", hjust = 0),
                angle = 90, color = "grey30", size = 3) +
      geom_text(aes(x = 0, y = alliance.level, label = "Alliance", hjust = 0),
                angle = 90, color = "grey30", size = 3)+
      # add label to graph 
      # geom_text(data=coph_annotation, aes( x=x, y=y, label=label), 
      #           color="black", 
      #           size=3 , angle=0, fontface="bold" ) +
      # annotate(cophenetic, x = .1, y = .1,
      #      label = "Cophonetic" , color="orange",
      #       size=7 , angle=0, fontface="bold")+
      coord_flip()+
      scale_y_reverse(limits = c(1, -.3))+
      labs(x = "", y = "Difference")+
      theme_minimal()+
      theme(axis.text.y=element_blank(), axis.title.y = element_blank())+
      ggtitle(paste0("Cluster Dendrogram of Site Units: branch ", i, " at hcut = ", cut.level))
    print(yy)
  }
  #print(paste0("The total number of site units is ", ss.count))
  print(paste0("The number of singles at hcut ", cut.level, " is ", singles.count))
 return(singles.list)
}

draw_edaphic_dendro(dist.mtrx = edaphic_matrix, subass.level = 0.07, assoc.level = 0.2, alliance.level = 0.4, cut.level = 0.5)

```


```{r}

library(pheatmap)
dis.matrix <- bec_dist_matrix(unit.compare3) 
pheatmap(dis.matrix, clustering_method = "average",
  fontsize_row = 6,  # adjust for row labels
  fontsize_col = 6   # adjust for column labels
)
```

#### Report units that are singles below the association threshold

```{r tables of singles units, echo=FALSE}
singles.poor <- as.data.frame(singles) %>% filter(grepl('nplot|lowdiag', SiteUnit))
singles.good <- as.data.frame(singles) %>% filter(!grepl('nplot|lowdiag', SiteUnit))

gt::gt(singles.good) %>%
  gt::tab_header(
    title = paste0(gt::md("Units ungrouped at cut.level = "), cut.level),
    subtitle = gt::md("*Units with sufficient plots and diagnostics*")
  )  %>%
  gt::tab_options(
   table.font.size = gt::px(10)
  )
gt::gt(singles.poor) %>%
  gt::tab_header(
    title = paste0(gt::md("Units ungrouped at cut.level = "), cut.level),
    subtitle = gt::md("*Units with deficient plots and diagnostics*")
  )  %>%
  gt::tab_options(
    table.font.size = gt::px(10)
  )


```

#### 

```{r pull associations from dendrogram at cut.level, echo=FALSE}

assocs <- cluster_groups(unit.compare, cut.level = 0.17, minclus = 0, group.label = "Association_clst")
assocs <- full_join(assocs, merge ) %>% filter(!SiteUnit %in% mergedUnit) %>% 
  mutate(Association_clst = ifelse(!is.na(mergedUnit), mergedUnit, Association_clst)) %>% 
  mutate(mergedUnit = ifelse(is.na(mergedUnit), SiteUnit, mergedUnit)) %>% mutate(Association_clst = paste0("assoc-", Association_clst))
alliances <- cluster_groups(unit.compare, cut.level = 0.35, minclus = 0, group.label = "Alliance.clst")
alliances  <- left_join(assocs, alliances ,  by = c("mergedUnit"="SiteUnit"), keep = TRUE) %>% select(Alliance.clst, Association_clst, SiteUnit.x, mergedUnit)%>% mutate(Alliance.clst = paste0("all-", Alliance.clst))
orders <- cluster_groups(unit.compare, cut.level = 0.8, minclus = 0, group.label = "Order.clst")
orders  <- left_join(alliances, orders,  by = c("mergedUnit"="SiteUnit"), keep = TRUE) %>% select(-SiteUnit, Order.clst, Alliance.clst, Association_clst, SiteUnit.x, mergedUnit)%>% mutate(Order.clst = paste0("order-", Order.clst))
classes <- cluster_groups(unit.compare, cut.level = .99, minclus = 0, group.label = "Class.clst")
classes  <- left_join(orders,classes,  by = c("mergedUnit"="SiteUnit"), keep = TRUE) %>% select(SiteUnit.x, Association_clst, Alliance.clst, Order.clst, Class.clst, mergedUnit)%>% mutate(Class.clst = paste0("class-", Class.clst))

subassocs <- cluster_groups(unit.compare, cut.level = 0.07, minclus = 0, group.label = "SubAssociation_clst")
subassocs <- full_join(subassocs, merge ) %>% filter(!SiteUnit %in% mergedUnit) %>% 
  mutate(SubAssociation_clst = ifelse(!is.na(mergedUnit), mergedUnit, SubAssociation_clst)) %>% 
  mutate(mergedUnit = ifelse(is.na(mergedUnit), SiteUnit, mergedUnit)) %>% mutate(SubAssociation_clst = paste0("subass-", SubAssociation_clst))
allunits <-  left_join(classes, subassocs,  by = c("mergedUnit"="SiteUnit"), keep = TRUE) %>% select(SiteUnit.x, SubAssociation_clst, Association_clst, Alliance.clst, Order.clst, Class.clst)#%>% mutate(Class.clst = paste0("class-", Class.clst))
su.temp <- su %>% select(PlotNumber, SiteUnit.orig, SiteUnit)
su3 <- left_join(su.temp, su, by = "PlotNumber")

#, by = c("SiteUnit" = "SiteUnit.y")) %>% select(PlotNumber, SiteUnit, Association, Alliance, Order, Class)
#singles <- assocs %>% filter(Association == 0)
## if minclus = 2 then group 0 are singles for review
## need to add back in the manually grouped site units
## need to change the accepted singles from zero to other association number if for review
# db <- "D:/BC_Correlation2_Vpro_2023/CoastGuide_Forested.accdb"
# su.coast <- combined_su(db)
# su.coast <- su.coast %>%
#   filter(!grepl('101a.2|101b.2|low|-S|add|nudum|poor|yc|_W|_F|ys|moved|X|unplaced', SiteUnit))
# su.coast <- su.coast %>% mutate(SiteUnit = str_replace(SiteUnit, "b$|a$", "")) %>% distinct()
# su.coast <- su.coast %>% filter(!bgc %in% c('CWHvh3', 'CWHwh1', 'CWHwh2', 'CWHvh3', 'MHwh'))
coast.units.su <- left_join(allunits, su3,  by = c("SiteUnit.x" = "SiteUnit.x")) %>% select(PlotNumber, SiteUnit.x, SiteUnit.orig.x, SubAssociation_clst,Association_clst, Alliance.clst, Order.clst, Class.clst, bgc) %>% rename(SiteUnit = SiteUnit.orig.x) %>% 
  group_by(SiteUnit) %>%  mutate(n = n()) %>% ungroup
# interior.units <- orders %>% filter(!Association == 0) %>%
#    filter(!SiteUnit.y %in% coast.units$SiteUnit) %>%
#   filter(Association %in% coast.units$Association)%>%
#   left_join(su) %>%
#   select(PlotNumber, SiteUnit, Association, Alliance, Order)
#coast.units.su <- rbind(coast.units, interior.units)
coast.units <- coast.units.su %>% select(-PlotNumber) %>% distinct 
colnames(coast.units) <- gsub('[.]', '_', colnames(coast.units))
fwrite(coast.units.su, "./clean_data/Association_Units_v1.csv")
fwrite(coast.units, "./clean_data/Coast_Hierarchical_Clusters_v1_clean.csv")
unit.counts <- coast.units %>% summarise_all(n_distinct)
gt::gt(unit.counts)
bgc.units<- dbConnect(
  odbc::odbc(),
  .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/OneDrive - Government of BC/BECdb_Working/BECdb_ver13_2024.accdb;")
dbWriteTable(bgc.units, "LMH77_hierunits_v2", coast.units, overwrite = TRUE, batch_rows = 1)
dbDisconnect(bgc.units)
```

#### Export vegetation summary tables of site units by prospective associations

```{r build veg guide summary and export to excel, echo = FALSE, warning=FALSE, message=FALSE}
require(openxlsx)
require(tictoc)
library(stringr)
data.path = "D:/OneDrive - Government of BC/GitHub_data"
author <- "test.assoc2"
assoc.list <- coast.units %>% filter(!is.na(Association_clst)) %>% group_by(Association_clst) %>% mutate(n=n()) %>% filter(n>2) %>% distinct(Association_clst) %>% pull(Association_clst)

vegsum.wbk <- createWorkbook()
for(assoc.choose in assoc.list){
#assoc.choose = "assoc-13"
assoc <- coast.units.su %>% filter(Association_clst %in% assoc.choose) %>% select(SiteUnit, Association_clst) %>% mutate(SiteUnit = gsub(" ", "", SiteUnit)) %>% mutate(SiteUnit = str_replace(SiteUnit, "/", "_"))
su.assoc <- left_join(assoc, su, by = "SiteUnit") %>%  mutate(SiteUnit = str_replace(SiteUnit, "b$|a$", "")) %>% distinct()
veg.dat.assoc <- veg.dat2 %>% filter(PlotNumber %in% su.assoc$PlotNumber)
# vegsum.wbk <- createWorkbook()
# #bgc.choose = "CDFmmtab2"
# #for(bgc.choose in bgc.list){
vegSum <-
  create_veg_sum_all(vdat = veg.dat.assoc, siteUnits = su.assoc, strata.by = "Lifeform")

indic.order <- build_species_ordering_hier(vdat = veg.dat.assoc, vsum = vegSum, code.lump=lump, siteUnits = su.assoc, hier.level = "Association_clst")
veg.sum.table <- format_veg_table2(vsum = vegSum, spp=taxon.lifeform)
openxlsx::addWorksheet(vegsum.wbk, sheetName = assoc.choose)
openxlsx::writeData(vegsum.wbk, sheet = assoc.choose, veg.sum.table)
}

saveWorkbook(vegsum.wbk, paste0("./vegsum.tables/LMH77_draft_assoc_tables_v3_", author, ".xlsx"), overwrite = TRUE)

```

```{r build veg guide summary for alliances, echo = FALSE, warning=FALSE, message=FALSE}
# require(openxlsx)
# require(tictoc)
# library(stringr)
# data.path = "D:/OneDrive - Government of BC/GitHub_data"
# author <- "test.alliance2"
# #coast.units <- coast.units %>% mutate(Alliance.clst = Alliance.clst)
# assoc.list <- coast.units %>% filter(!is.na(Alliance.clst)) %>% group_by(Alliance.clst) %>% mutate(n=n()) %>% filter(n>2, n<15) %>% distinct(Alliance.clst) %>% pull(Alliance.clst)
# 
# vegsum.wbk <- createWorkbook()
# for(assoc.choose in assoc.list){
# #assoc.choose = "all-42"
# assoc <- coast.units.su %>% filter(Alliance.clst %in% assoc.choose) %>% select(SiteUnit, Alliance.clst) %>% mutate(SiteUnit = gsub(" ", "", SiteUnit)) %>% mutate(SiteUnit = str_replace(SiteUnit, "/", "_"))
# su.assoc <- left_join(assoc, su, by = "SiteUnit") %>%  mutate(SiteUnit = str_replace(SiteUnit, "b$|a$", "")) %>% distinct() 
# veg.dat.assoc <- veg.dat2 %>% filter(PlotNumber %in% su.assoc$PlotNumber)
# # vegsum.wbk <- createWorkbook()
# # #bgc.choose = "CDFmmtab2"
# # #for(bgc.choose in bgc.list){
# vegSum <-
#   create_veg_sum_all(vdat = veg.dat.assoc, siteUnits = su.assoc, strata.by = "Lifeform")
# tic()
# indic.order <- build_species_ordering_hier(vdat = veg.dat.assoc, vsum = vegSum, code.lump=lump, siteUnits = su.assoc, hier.level = "Alliance.clst")
# toc()
# veg.sum.table <- format_veg_table2(vsum = vegSum, spp=taxon.lifeform)
# openxlsx::addWorksheet(vegsum.wbk, sheetName = assoc.choose)
# openxlsx::writeData(vegsum.wbk, sheet = assoc.choose, veg.sum.table) 
# }
# 
# saveWorkbook(vegsum.wbk, paste0("./vegsum.tables/LMH77_draft_hierarchy_tables_", author, ".xlsx"), overwrite = TRUE)

```

Merge in hierarchical cluster numbers to BECdb tables to help guide naming of units

```{r add in association code}
# table <- "tblBEC_SiteSeries_LMH77_forest"
# becdb <- dbConnect(odbc::odbc(), .connection_string = "Driver={Microsoft Access Driver (*.mdb, *.accdb)}; DBQ=D:/OneDrive - Government of BC/BECdb_Working/BECdb_ver13_2024.accdb;")
# SS_v13 <- dbReadTable(becdb, table)
# SS_v13_2 <- setDT(SS_v13)[setDT(coast.units), `:=`(Association_Code = Association_clst, Alliance = Alliance.clst, Order = Order.clst, Class = Class.clst), on = c("SS_Label" = "SiteUnit")]
# dbRemoveTable(becdb, table)
# dbWriteTable(becdb, table, SS_v13_2, append = TRUE, batch_rows = 1)
# dbDisconnect(becdb)

```

Convert to a hierarchy structure

```{r to Vpro hierarchy, echo=FALSE}
# coast.hier <- coast.units %>% mutate(Formation = "not_set", Suborder = "", Suball = "" , Subass = "" , Facies = "" , Working = "") %>% rowid_to_column("ID") %>%  select(ID, Formation, Class, Order, Suborder, Alliance, Suball, Association, Subass, Facies, Working, SiteUnit) %>% distinct %>% rename(Assoc = Association) %>%  mutate_if(is.numeric, as.character) %>%  mutate(ID = as.integer(ID)) %>% as.data.table
# levelNames <- c("Formation", "Class", "Order", "Suborder", "Alliance", "Suball", "Assoc", "Subass", "Facies", "Working", "SiteUnit")
# testReverse <- tableToTree(hierWide = copy(test),levelNames) ## convert matrix to tree
# testReverse <-testReverse %>% mutate(Parent = ifelse(Parent == 0, NA, Parent)) %>% distinct(Name, .keep_all = TRUE)
# fwrite(testReverse, "./outputs/UpdatedCoastHierarchy_v13_1.csv")
```



#### some testing of cluster methods evaluate the cophonetic and cluster ability of different methods

```{r split dendrogram1, echo=FALSE}
# evaluate_gaverage_grid <- function(unit.compare) {
#   # Create parameter grid
#   param_grid <- expand.grid(
#     alpha = seq(0, 1, by = 0.1),
#     beta  = seq(0.0, 1, by = 0.1),
#     gamma = seq(0.0, 1, by = 0.1),
#     stringsAsFactors = FALSE
#   )
# 
#   # Distance matrix
#   dis.matrix <- bec_dist_matrix(unit.compare)
#   dis.dis <- as.dist(dis.matrix)
# 
#   results <- param_grid
#   results$cophenetic_corr <- NA
#   results$agglomerative_coeff <- NA
# 
#   # Loop through each parameter combination
#   for (i in 1:nrow(param_grid)) {
#     par.method <- c(param_grid$alpha[i], param_grid$alpha[i], param_grid$beta[i], param_grid$gamma[i])
#     
#     model <- tryCatch({
#       agnes(dis.matrix, diss = TRUE, stand = TRUE, method = "gaverage", par.method = par.method)## can replace with "flexible" method
#     }, error = function(e) NULL)
# 
#     if (!is.null(model)) {
#       results$cophenetic_corr[i] <- round(cor(dis.dis, cophenetic(model)), 3)
#       results$agglomerative_coeff[i] <- round(model$ac, 3)
#     }
#   }
# 
#   return(results)
# }
# 
# library(ggplot2)
# library(tidyr)
# library(dplyr)
# 
# gavg_results <- evaluate_gaverage_grid(unit.compare)
# 
# # Plot cophenetic correlation as a heatmap
# ggplot(gavg_results, aes(x = beta, y = gamma, fill = cophenetic_corr)) +
#   facet_wrap(~ alpha, labeller = label_bquote(alpha == .(alpha))) +
#   geom_tile(color = "white") +
#   scale_fill_viridis_c(option = "C", name = "Cophenetic\nCorrelation") +
#   labs(title = "CCC Across Generalized Average Linkage Parameters",
#        x = "", y = "") +
#   theme_minimal(base_size = 14)
```

```{r split dendrogram2, echo=FALSE}
# library(cluster)
# library(dplyr)
# 
# evaluate_flexible_clustering <- function(unit.compare, par_seq = seq(0, 1, by = 0.05)) {
#   results <- data.frame(par.method = numeric(),
#                         agglomerative_coeff = numeric(),
#                         cophenetic_corr = numeric())
#   
#   for (p in par_seq) {
#     #ss_clst <- agnes(dis.matrix, diss = TRUE, stand = TRUE, method = "flexible", par.method = p)
#     ss_clst <- agnes(dis.matrix, diss = TRUE, stand = TRUE, method = "flexible", par.method = p)
#     cophenetic_corr <- cor(dis.dis, cophenetic(ss_clst))
#     agglom_coeff <- round(ss_clst$ac, 3)
#     # cophenetic_corr2 <- cor(dis.dis, cophenetic(ss_clst2))
#     # agglom_coeff2 <- round(ss_clst2$ac, 3)
#     
#     results <- rbind(results, data.frame(par.method = p,
#                                          agglomerative_coeff = agglom_coeff,
#                                          cophenetic_corr = round(cophenetic_corr, 3)))
#   }
#   return(results)
# }
# cluster_eval <- evaluate_flexible_clustering(unit.compare = unit.compare)
# # Convert to long format for faceted plotting
# cluster_eval_long <- cluster_eval %>%
#   pivot_longer(cols = c(agglomerative_coeff, cophenetic_corr),
#                names_to = "metric", values_to = "value")
# 
# # Plot both metrics
# ggplot(cluster_eval_long, aes(x = par.method, y = value, color = metric)) +
#   geom_line(size = 1.2) +
#   geom_point(size = 2.5) +
#   scale_x_continuous(breaks = seq(0.1, 0.9, by = 0.1)) +
#   scale_color_manual(values = c("#1b9e77", "#d95f02")) +
#   labs(
#     title = "Clustering Evaluation Across par.method Settings",
#     x = "par.method (flexible clustering penalty)",
#     y = "Metric Value",
#     color = "Metric"
#   ) +
#   theme_minimal(base_size = 14) +
#   theme(legend.position = "top")
```