---
title: "MachineLearningHigherOrders"
author: "Will MacKenzie & Kiri Daust"
date: "05/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

require(tidyverse)
require(tidymodels)
require(data.table)
require(data.tree)
require(DataExplorer)
require(C50)
require(indicspecies)
```

1. A machine learning model of high-level hierarchical BEC Forest units
a. Create a ML model of Forested Orders using BECv11 site series that meet minimum plot requirements.
b. Use only tree species for first round of model build for the forested Orders.
c. Predict membership of new BECv12 units and assign to orders then rebuild ML model.
d. Review any mis predicted site series for reassignment.
e. Compare similarity of tree composition within units (noise clustering) to find outliers that may represent new Orders (test by leaving out known units)
f. Create vegetation summaries of Orders and compare vegetation (all species now). Identify climatic indicator species groups.
g. Create climatic and site attributes summary of Orders 
h. Create maps of plot locations for each Order

2. Do pair-wise analysis of site series within Orders using high constancy species to analyze site series and create Associations/SubAssociations.

3. Build Alliances. Focus should be on identifying species groups that reflect different site conditions.
a. Use some of the techniques of indicspecies package to create Alliances based on indicator group creation and analysis.
b. Try to build a machine learning model of Alliances
c. Vegetation and Environment summary of Alliances

4. Document hierarchy

5. Build model to assign new units and unassigned plots
Challenge here is to make a constant list of species between model and new units.
a. Predict membership of new site series (draft BECv13). Noise Clustering to test for novel units that do not fit any existing. Use machine learning to hierarchy
b. Predict Order membership of BECMaster plots that are unassigned to existing site series and add to an Order_unplaced site unit under each Order.

6. Build for non-forested units. Classes based on major site level differences rather than climate and using major species groups (e.g. Hydrophytic Carex spp )
May wish to assign a temporary notree pseudo species to all units that have no trees to help separate forested hierarchy from non-forested hierarchy (Hurdle model)

```{r import data}
### Vegetation From BECMaster cleaning script Long form Plot|Species|Cover (across all layers)
### or From Vpro export

vegDat2 <- fread('./inputs/BECMaster_VegR_clean.csv')
sppMaster <- fread('./inputs/SpeciesMaster05Oct2019.csv')
#####################importing Vpro veg data########################################
############### Uses 3 column R export FORMAT FROM Vpro with Lifeform option selected
#load("./inputs/VegDat_Raw.RData")##includes type field for lifeform
#vegDat2 <- vegData %>% filter(!is.na(Type))
###SU table
SUTab <- fread("./inputs/BECMster_V2020_2_SU.csv")
SUTab$SiteUnit <-  trimws(SUTab$SiteUnit)
SS.names <- unique(SUTab$SiteUnit)

#####list of official current and future correlated units from BECdb
current <- c('Current', 'Future')
ecotypes <- c("Forest", "Deciduous")
#### cleaned list of official site series
BECdb_SS <- fread("./inputs/BECdb_SiteSeriesv12.csv") %>% filter(Status %in% current) %>% filter(ArchivedinVersion == "") %>% filter(`Forest-NonForest` %in% ecotypes) %>% 
  select(MergedBGC_SS, SS_NoSpace, SiteSeriesLongName, SiteSeriesScientificName) %>% rename (SiteUnit = 1, SSName = 3, SciName = 4) %>% distinct(SiteUnit, .keep_all = TRUE)
#### compare SUTab to BECdb.  Whan all BECdb units to have data and SUTab to include no unofficial units
SS_missing <- full_join(SUTab, BECdb_SS) %>% filter(is.na(PlotNumber))
##Import Vpro hierarchy table widen and reformat
SUhier <- fread("./inputs/BECv12_Forests_July2020_Hierarchy.csv")
### add any site units not in hierarchy to hierarchy

```


```{r clean hierarchy}
treeToTable <- function(SUhier){
  hierLookup <- SUhier[,.(ID,Name)]
  HierClean <- SUhier[,.(ID,Parent,Name,Level)]
  roots <- HierClean$Parent[!HierClean$Parent %in% HierClean$ID]
  roots <- unique(roots[!is.na(roots)])
  if(length(roots) >= 1){
    warning("There are duplicate roots. Please check ID ", roots)
  }
  HierClean[is.na(Parent), Parent := 1]
  temp <- data.table(ID = roots,Parent = rep(1,length(roots)), Name = rep("XXX",length(roots)),Level = rep(1, length(roots)))
  HierClean <- rbind(HierClean,temp)
  
  HierClean[hierLookup, ParentName := i.Name, on = c(Parent = "ID")]
  HierClean[is.na(ParentName), ParentName := "root2"]
  HierClean <- HierClean[,.(Name,ParentName,Level)]
  HierClean$ParentName[!HierClean$ParentName %in% HierClean$Name]
  tree <- FromDataFrameNetwork(HierClean)
  wideTab <- ToDataFrameTypeCol(tree)
  wideTab <- as.data.table(wideTab)
  wideTab[,ID := 1:nrow(wideTab)]
  wideTab[,level_1 := NULL]
  tab2 <- melt(wideTab, id.vars = "ID")
  tab2 <- na.omit(tab2)
  tab2[HierClean, Level := i.Level, on = c(value = "Name")]
  dupLevels <- tab2[,.(Len = .N), by = .(ID,Level)]
  dupLevels <- dupLevels[Len > 1,]
  dups <- tab2[ID %in% dupLevels$ID,]
  setorder(dups,"ID")
  dups[,variable := NULL] ##these are the branches with duplicates
  tabOut <- dcast(tab2, ID ~ Level, value.var = "value", fun.aggregate = function(x){x[1]})
  setnames(tabOut, c("ID","Formation","Class","Order","Suborder","Alliance","Suball","Assoc","Subass","Facies", "Working", "SiteSeries"))
  tabOut[is.na(Subass), Subass := Assoc]
  tabOut[is.na(Suborder), Suborder := Order]
  tabOut[is.na(Suball), Suball := Alliance]
  return(list(table = tabOut, duplicates = dups))
}

temp <- treeToTable(SUhier)
Hier.clean <- temp$table
fwrite(Hier.clean, './inputs/cleanedHierarchy.csv')

```

```{r check units in hierarchy}
### remove units not in BECdb

### add in official unit missing in hierarchy

```



```{r summarize site series, echo=FALSE}

#SUTab <- fread("./inputs/BECMster_V2020_2_SU.csv")
### Summarize by SU including mean cover and constancy percent
##roll up into site series summary data
### Filter out all species but tree species
trees = c("1", "2") ### include only trees for hierarchy build
vegDat2 <- as.data.table(vegDat2)
vegDat_test <- vegDat2[Lifeform %in% trees,]
vegDat_test <- vegDat_test %>% dplyr::filter(Cover > 0.1)

constCut <- 0.1 ##remove species less than cutoff
vegDat <- as.data.table(vegDat_test)

vegDat[SUTab, SiteUnit := i.SiteUnit, on = "PlotNumber"]
vegDat <- unique(vegDat[!is.na(SiteUnit) & SiteUnit != "",])
vegDat3 <- vegDat[,if(.N > 1) .SD, by = .(SiteUnit,Species)]
vegDat3[,nPlots := length(unique(PlotNumber)), by = .(SiteUnit)]
vegSum <- vegDat3[,.(MeanCov = sum(Cover)/nPlots[1], Constancy = (.N/nPlots[1])*100, nPlots = nPlots[1]), by = .(SiteUnit,Species)]
#vegDat <- as_tibble(vegDat)
# vegDat$SiteUnit <- as.factor(vegDat$SiteUnit)
# vegDat3 <- vegDat %>% group_by(SiteUnit, Species) %>% filter(n() > 1)

# vegDat3 <- vegDat %>% group_by(SiteUnit, Species) %>% mutate(nPlots = n_distinct(PlotNumber))
# vegDat <- as.data.table(vegDat)

#-------------problem with the mean cover calculation
# 
# vegSum <- vegDat[,.(MeanCov = sum(Cover)/nPlots[1], Constancy = (.N/nPlots[1])*100, nPlots = nPlots[1]), by = .(SiteUnit,Species)] %>% mutate(across(where(is.numeric), round, 3))

fwrite(vegSum, './inputs/SiteSeriesConiferSummary.csv')

##build grand summary table that then can be reduce to only species with high constancy in a least one unit. Probably not too useful for very large analyses

#### linkages to Site Association Analysis Units from other script will replace this.

```


```{r filter and prepare for analysis}
#Hier.clean <- fread("./inputs/cleanedHierarchy.csv")
#vegSum <- fread('./inputs/SiteSeriesForestedSummary.csv')

SS_good <- vegSum %>% filter(nPlots >=3) %>% filter(Constancy >= 33) %>% rename(SiteSeries = SiteUnit) %>% distinct()## Select only site series will enough plots
Hier.units <- Hier.clean %>% select(SiteSeries, Class, Order, Suborder) %>% distinct()
#Hier.units <- Hier_update%>% select(SiteSeries, Class, Order, Suborder)
Hier.data <- left_join(Hier.units, SS_good) %>% filter(!is.na(nPlots)) %>% arrange(Species) %>% distinct()
fwrite(Hier.data, './inputs/SiteSeriesForested_w_HierarchyUnits.csv')
```

```{r some hierarchy stats}
classes <- unique(Hier.data$Class)
orders <- unique(Hier.data$Order)
suborders <- unique(Hier.data$Suborder)
class.dat <-
  Hier.data %>% select(SiteSeries, Class, Species, MeanCov) %>% 
  pivot_wider(id_cols = c(SiteSeries, Class),
    names_from = Species,
    values_from = MeanCov) %>% 
  mutate(Class = replace_na(Class, "unplaced")) %>% filter(!SiteSeries == "") %>% 
   replace(is.na(.),0) %>% 
  mutate_if(is.character, as.factor) %>% distinct()

#DataExplorer::create_report(class.dat)
```
Data pre-processing includes the following steps:  

```{r prep data, include = TRUE, echo = FALSE}

classID <- class.dat %>% select(SiteSeries, Class)
#class.dat2 <- class.dat %>% select(-SiteUnit)
BEC_all <- class.dat %>% arrange(SiteSeries)
SU_names <- as.data.frame(BEC_all$SiteSeries) %>%  distinct() %>% rowid_to_column('.row') %>% rename("SiteSeries" = 2)
# 1: split into training and test data (0.75/0.25) training and testing 

# BEC_split <-  initial_split(BEC_all, 
#                               strata = Class,
#                               prop = 0.9)
#   
# BEC_train <- training(BEC_split)
# BEC_test <- testing(BEC_split)
BEC_recipe <-
    recipe(Class ~ ., data = BEC_all) %>%
     update_role(SiteSeries, new_role = "id variable") %>% 
  #update_role(-SiteUnit, new_role = "predictor") %>% 
    #step_corr(all_numeric()) %>%        # remove correlated covariates
    #step_dummy(all_nominal(),-all_outcomes()) %>%    
    #step_zv(all_numeric()) %>%          # remove values with no variance
   # step_smote(Class) %>%
    prep() 
    summary(BEC_recipe)

# note in RF as a tree based model it is not required to scale and normalize covariates and may have negative influence on the model performance  
```

## Tuning run to identify appropriate hyper parameters. Only needs to be run a single time for a particular model development

```{r model tuning, include = FALSE, echo = FALSE}

# BEC_tunemodel <- rand_forest(mtry = tune(), min_n = tune(), trees = 501) %>%
#   set_mode("classification") %>%
#   set_engine("ranger", importance = "impurity") #or "permutations
# 
# # randf_spec <- rand_forest(trees = 500) %>%
# #   set_engine("randomForest") %>%
# #   set_mode("classification")
# 
# BEC_tuneworkflow <- workflow() %>%
#   add_model(BEC_tunemodel) %>%
#     add_recipe(BEC_recipe)
# 
# ranger_tune_detail <-
#   grid_regular(
#     mtry(range = c(1, 20)),
#     min_n(range = c(2, 10)),
#     levels = 5)
# 
# cv_metrics <- metric_set(accuracy, roc_auc, j_index)
# 
# v = 10
# reps = 5
# set.seed(345)
# BEC_cvfold <- vfold_cv(BEC_all, 
#                          v = v, 
#                          repeats = reps, 
#                          strata = Class)
# # re-run the tuning with the explicit parameter sets
# set.seed(4556)
# doParallel::registerDoParallel()
# 
# ranger_regular_tune <-
#   tune_grid(BEC_tuneworkflow,
#             resamples = BEC_cvfold,
#             metrics = cv_metrics,
#             grid = ranger_tune_detail)
# 
# autoplot(ranger_regular_tune) ##plots the results
# 
# bestacc <- select_best(ranger_regular_tune, metric = "accuracy")
# bestroc <- select_best(ranger_regular_tune, metric = "roc_auc")
# bestj <- select_best(ranger_regular_tune, metric = "j_index")

```

## Run cross validation model of all data using tuning from previous step
```{r define cv model with tuned parameters, echo = TRUE }
# define model with set parameters from tuning

BEC_fmodel <- rand_forest(mtry = 5, min_n = 2, trees = 501) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "impurity") #or "permutations

BEC_cv_workflow <- workflow() %>% 
  add_model(BEC_fmodel) %>% 
  add_recipe(BEC_recipe)

v = 10
reps = 5
  
set.seed(345)
BEC_cvfold <- vfold_cv(BEC_all, 
                         v = v, 
                         repeats = reps, 
                         strata = Class)
cv_metrics <- metric_set(accuracy, roc_auc, j_index, sens, spec)

set.seed(130)
doParallel::registerDoParallel()
BEC_cv_fitted <- 
  BEC_cv_workflow %>% 
  fit_resamples(resamples = BEC_cvfold, metrics = cv_metrics, control = control_resamples(save_pred = TRUE))
```

## Collect accuracy metrics and predictions and improperly predicted site units
```{r collect metrics and predictions, echo = TRUE }
# collect accuracy metrics  
cv_results <- BEC_cv_fitted  %>% collect_metrics(summarize = FALSE)
cv_results_sum <- BEC_cv_fitted  %>% collect_metrics()
BEC.pred <- BEC_cv_fitted %>% collect_predictions()# collect predictions
BEC.predx <- left_join( BEC.pred, SU_names)
### accuracy by siteunit
BEC.pred_acc <- BEC.pred %>% 
  group_by(Class) %>% 
  accuracy(Class, .pred_class)
#Summarize prediction
BEC.pred2 <- BEC_cv_fitted %>% collect_predictions(summarize = TRUE)# collect predictions
BEC.pred3 <- left_join(SU_names, BEC.pred2)

## Identify misplaced site units
MisID <- BEC.pred3 %>% select(SiteSeries, Class, .pred_class) %>% mutate(compare = if_else(Class == .pred_class, "Same", "Diff")) %>% filter(compare == "Diff")# %>% rename("SiteSeries" = SiteUnit)
fwrite(MisID, "Misplaced Site Series in Classes.csv")

##ID where there are different classifications predicted by fold **** this is not aligning SU_names properly
# BEC.pred_cv <- BEC_cv_fitted %>% collect_predictions(summarize = FALSE) %>% left_join(SU_names) %>% select(SiteUnit, Class, .pred_class) %>% group_by_all() %>% summarize(numcv = n())#distinct# dplyr::rename(BEC.pred = 3) %>% 
# setDT(BEC.pred_cv, key = c("SiteUnit"))
# BEC.pred_cv[, N := .N, by = key(BEC.pred_cv)]                # count rows per group
# class.diff <- BEC.pred_cv[N > 1]

```
## review and reassign site units to correct hierarchy units
```{r reassign units}
##Update class by MisID in BEC_all (to build final model) and in Hier.clean (to update the hierachy table)
UpdateClass <- MisID %>% select(SiteSeries, .pred_class)
Hier_update <- left_join(Hier.clean, UpdateClass, by  = "SiteSeries") %>% mutate(newClass = coalesce(.pred_class, Class)) %>% select(-Class, -.pred_class) %>% rename(Class = newClass) %>% select(ID, Class, everything())
```

```{r reverse function to write hierarhcy back into Vpro format}
levelNames <- c("Region", "Class", "Order", "Suborder", "Alliance", "Suball", 
"Assoc", "Subass", "Facies", "SiteSeries")

tableToTree <- function(hierWide, levelNames){
  levelID <- data.table(Name = levelNames, Level = 1:length(levelNames))
  
  levs <- melt(hierWide, id.vars = "ID")
  levs[,ID := NULL]
  levs <- unique(levs)
  levs[levelID, Level := i.Level, on = c(variable = "Name")]
  
  hierWide[,ID := NULL]
  hierWide[,Root := "TempRoot"]
  setcolorder(hierWide,c(ncol(hierWide),1:(ncol(hierWide)-1)))
  paths <- tidyr::unite(hierWide, "pathString", na.rm = T, sep = "_")
  tr <- as.Node(paths,pathDelimiter = "_")
  tr$Set(Lab = tr$Get("name"))
  tr$Set(name = 1:tr$totalCount)
  dat <- ToDataFrameNetwork(tr,"Lab",direction = "climb")
  dat <- as.data.table(dat)
  setnames(dat, old = c("from","to","Lab"), new = c("Parent","ID","Name"))
  dat[levs, Level := i.Level, on = c(Name = "value")]
  setcolorder(dat,c("ID","Name","Parent","Level"))
  return(dat)
}


testReverse <- tableToTree(hierWide = copy(Hier.clean),levelNames)
```

```{r build final model, include = FALSE}

# 2: set up cross validation for parameter tuning data sets # note vc is default to 10 fold
BEC_workflow <- workflow() %>%
  add_model(BEC_fmodel) %>% 
    add_recipe(BEC_recipe)

BEC_ranger_model <- fit(BEC_workflow, BEC_all)
BEC_ranger_model$fit

```

```{r C5 decision tree}
#For interpretation of hierarchy
#Cross-validation.

#BEC_C5_recipe <- recipe(Class ~ .,  data = BEC_all)# %>%
    #step_center(all_predictors()) %>%
 # step_scale(all_predictors())
BEC_C5_model <- decision_tree(min_n = 2) %>% #, trees = NULL, min_n = NULL)# trees = 5, min_n = 2min_n = 10specify that the model is a random forest
  #set_args(mtry = tune()) %>% specify that the `mtry` parameter needs to be tuned
  set_engine("C5.0") %>%  #, num.threads = (cores-1), importance = "impurity, ) %>% select the engine/package that underlies the model
   set_mode(mode = "classification")

 # set the workflow
BEC_C5_workflow <- workflow() %>%
  add_recipe(BEC_recipe) %>%
  add_model(BEC_C5_model)
#
BECmodel.C5 <- fit(BEC_C5_workflow, BEC_all)
out <- butcher(BECmodel.C5, verbose = TRUE)


C5model <- C5.0_train(class.dat, Class, minCases = 2)
C5model <- C5.0(x=class.dat[-1], y = class.dat$Class)
C5model
summary(C5model)
plot(C5model)

## build model for prediction

gc()

 BECmodel.var <- pull_workflow_fit(BECmodel.tidy)$fit
BEC.pred <-   as.data.frame(BECmodel.var$predicted)
MisID <- cbind(classID,BEC.pred)%>% dplyr::rename(BEC.pred = 3) %>% mutate(compare = if_else(Class == BEC.pred, "Same", "Diff"))
fwrite(MisID, "Misplaced Site Series in Classes.csv")
###Variable importance
varimp <- as.data.frame(BECmodel.var$importance)
covcount <- nrow(varimp)


#saveRDS(BGCmodel.tidy, file = paste("./BGC_models/WNAv12_Zone_", covcount, "_Var_tidyrf3.rds"))
#parsed <- parse_model(BGCmodel.var)
#write_yaml(parsed, "my_model.yml")
saveRDS(BECmodel.tidy, file= paste("./BEC_models/Forest_Classes_rf.rds"))

```


```{r}
BEC_split <- initial_split(class.dat, strata = Class, p = .8)
BEC_train <- training(BEC_split)
BEC_test <- testing(BEC_split)


BEC_model <- rand_forest(trees = 101, mtry = tune()) %>%# min_n = 10specify that the model is a random forest
  #set_args(mtry = tune()) %>% specify that the `mtry` parameter needs to be tuned
  set_engine("randomForest", num.threads = (cores-1)) %>%  #, importance = "impurity, ) %>% select the engine/package that underlies the model
   set_mode("classification")

 # set the workflow
BEC_workflow <- workflow() %>%
  add_recipe(BEC_recipe) %>%
  add_model(BEC_model)
#
## build model for prediction
BECmodel.train <- BEC_workflow %>% fit(BEC_train)
 BECmodel.var <- pull_workflow_fit(BECmodel.train)$fit
 BECmodel.var


 # trainIndex <- createDataPartition(class.dat$Class, p = .7,
#                                   list = FALSE,
#                                   times = 1)
# 
# 
# BEC_train <- XAll[ trainIndex,]
# BEC_train$BEC <- as.factor(BEC_train$BEC)
# BEC_test  <- XAll[-trainIndex,]# %>% droplevels()

BECmodel_train <- ranger(BEC ~ ., data = BEC_train[-1],
                           num.trees = 501,  seed = 12345,
                            splitrule =  "extratrees", #""gini",
                            #always.split.variables = c("DD5","CMD.total", "PPT_JAS"), #,
                            #split.select.weights = var.weight.vec,
                    mtry = 5,
                          #max.depth = .5,
                    min.node.size = 5,
                           importance = "permutation", write.forest = TRUE, classification = TRUE)

BECmodel_train

 test.pred <- predict(BECmodel.train, new_data = BEC_test[,-c(1)])
  BEC.pred <- as.data.frame(test.pred) %>% tibble::rownames_to_column() %>% dplyr::rename("BEC.pred" = ".pred_class")

BEC.test <- BEC_test %>% select(Class) %>% cbind(BEC.pred) %>%  select( -rowname) %>% mutate_if(is.character, as.factor)
levels(BEC.test$BEC.pred) <- levels(BEC.test$BEC)
BEC_accuracy <- BEC.test %>%                   # test set predictions
  accuracy(truth = Class, BEC.pred)
 table(BEC_accuracy)
```

```{r review misassigned SS}

```

```{r predict placement of new SS and plots}



```

